{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892ac848-252a-4b16-975f-b19305ea177f",
   "metadata": {},
   "source": [
    "# è®°å¿†\n",
    "\n",
    "[è®°å¿†](https://docs.langchain.com/oss/python/langgraph/add-memory)ï¼ˆMemoryï¼‰æ˜¯ä¸€ä¸ªå¯é€‰æ¨¡å—ã€‚é™¤éžå¿…è¦ï¼Œä½ æ— éœ€å‘æ™ºèƒ½ä½“æ·»åŠ  Memory æ¨¡å—ã€‚å› ä¸º StateGraph æœ¬èº«å°±æœ‰åŽ†å²æ¶ˆæ¯çš„å­˜å‚¨åŠŸèƒ½ï¼Œè¶³ä»¥æ»¡è¶³æœ€åŸºç¡€çš„â€œè®°å¿†â€éœ€æ±‚ã€‚\n",
    "\n",
    "éœ€è¦æ·»åŠ  Memory æ¨¡å—çš„æƒ…å†µåŒ…æ‹¬ï¼š\n",
    "\n",
    "1. åŽ†å²æ¶ˆæ¯è¶…å‡ºé™åˆ¶ï¼Œéœ€è¦ä½¿ç”¨å¤–éƒ¨å·¥å…·å­˜å‚¨è®°å¿†\n",
    "2. è§¦å‘äººå·¥å¹²é¢„ï¼ˆ[interrupt](https://docs.langchain.com/oss/python/langgraph/interrupts)ï¼‰åŽï¼Œéœ€è¦ä¸´æ—¶å­˜å‚¨æ™ºèƒ½ä½“çŠ¶æ€\n",
    "3. éœ€è¦è·¨å¯¹è¯æå–ç”¨æˆ·åå¥½\n",
    "\n",
    "LangGraph å°†è®°å¿†åˆ†ä¸ºï¼š\n",
    "\n",
    "- [çŸ­æœŸè®°å¿†](https://docs.langchain.com/oss/python/langchain/short-term-memory)ï¼ˆMemorySaverï¼‰\n",
    "- [é•¿æœŸè®°å¿†](https://docs.langchain.com/oss/python/langchain/long-term-memory)ï¼ˆMemoryStoreï¼‰\n",
    "\n",
    "æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ª [LangMem](https://langchain-ai.github.io/langmem/) ä¹Ÿæä¾›è®°å¿†å­˜å–åŠŸèƒ½ã€‚\n",
    "\n",
    "> PS: ä¸çŸ¥é“å¼€å‘å›¢é˜Ÿä¸ºå•¥æŠŠè®°å¿†åˆ†å¾—è¿™ä¹ˆç¨€ç¢Žã€‚æ„Ÿè§‰è¿™äº›æ¨¡å—è¿˜ä¸æˆç†Ÿï¼ŒåŽè¾¹å˜åŠ¨ä¼šæ¯”è¾ƒå¤§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aff8836-8798-4920-b679-7abe02218d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# åŠ è½½æ¨¡åž‹é…ç½®\n",
    "_ = load_dotenv()\n",
    "\n",
    "# åŠ è½½æ¨¡åž‹\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# åˆ›å»ºåŠ©æ‰‹èŠ‚ç‚¹\n",
    "def assistant(state: MessagesState):\n",
    "    return {'messages': [model.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfc72f-332c-4c57-b0b7-88e961b79f87",
   "metadata": {},
   "source": [
    "## ä¸€ã€çŸ­æœŸè®°å¿†\n",
    "\n",
    "çŸ­æœŸè®°å¿†ï¼ˆå·¥ä½œè®°å¿†ï¼‰ä¸€èˆ¬ç”¨äºŽä¸´æ—¶å­˜å‚¨ï¼Œä¸Žå½“å‰å¯¹è¯å†…å®¹å¼ºç›¸å…³ã€‚ä¸Žä¾èµ–ä¸Šä¸‹æ–‡çš„è®°å¿†æ–¹å¼ä¸åŒï¼ŒçŸ­æœŸè®°å¿†å¯ä»¥ä¸»åŠ¨è®°ä½é‡è¦çš„å†…å®¹ï¼Œå¢žåŠ å·¥ç¨‹ç¨³å®šæ€§ã€‚\n",
    "\n",
    "### 1ï¼‰åœ¨ `StateGraph` ä¸­ä½¿ç”¨çŸ­æœŸè®°å¿†\n",
    "\n",
    "ä¸ºäº†æ–¹ä¾¿æ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨ `InMemorySaver` å­˜å‚¨çŸ­æœŸè®°å¿†ã€‚è¿™æ„å‘³ç€çŸ­æœŸè®°å¿†å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚å¦‚æžœé€€å‡ºå½“å‰ç¨‹åºï¼Œè®°å¿†å°†ä¼šæ¶ˆå¤±ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7794c6-13cb-4b0f-bf19-ef9bc6dc14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Luochang! It's great to meet you. How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºçŸ­æœŸè®°å¿†\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# åˆ›å»ºå›¾\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "builder.add_node('assistant', assistant)\n",
    "\n",
    "# æ·»åŠ è¾¹\n",
    "builder.add_edge(START, 'assistant')\n",
    "builder.add_edge('assistant', END)\n",
    "\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "# å‘Šè¯‰æ™ºèƒ½ä½“æˆ‘å« luochang\n",
    "result = graph.invoke(\n",
    "    {'messages': ['hi! i am luochang']},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c6c699-c2b8-466c-8877-877b3b40382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Luochang! It's great to meet you. How can I assist you today? ðŸ˜Š\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Luochang! ðŸ˜Š How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# è®©æ™ºèƒ½ä½“è¯´å‡ºæˆ‘çš„åå­—\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2b2f6-9cb0-4b9e-89a2-89de5d53d925",
   "metadata": {},
   "source": [
    "### 2ï¼‰åœ¨ `create_agent` ä¸­ä½¿ç”¨çŸ­æœŸè®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59286c68-a72d-4e92-b7b3-b81db8e0e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Luochang! It's nice to meet you. How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# åˆ›å»ºçŸ­æœŸè®°å¿†\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# å‘Šè¯‰æ™ºèƒ½ä½“æˆ‘å« luochang\n",
    "result = agent.invoke(\n",
    "    {'messages': ['hi! i am luochang']},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93509d9f-370f-4ea8-abdb-ae01fd51e112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Luochang! It's nice to meet you. How can I assist you today? ðŸ˜Š\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Luochang! ðŸ˜Š Is there anything I can help you with?\n"
     ]
    }
   ],
   "source": [
    "# è®©æ™ºèƒ½ä½“è¯´å‡ºæˆ‘çš„åå­—\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},  \n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf12a1a-0c98-4c61-9f23-12a829ee2251",
   "metadata": {},
   "source": [
    "ä¸ºäº†éªŒè¯ `InMemorySaver` æ˜¯å¦çœŸçš„æœ‰æ•ˆæžœï¼Œå¯ä»¥å°† `checkpointer=checkpointer` æ³¨é‡ŠåŽï¼Œå†è§‚å¯Ÿæ™ºèƒ½ä½“èƒ½ä¸èƒ½æ­£ç¡®å›žå¤æˆ‘çš„åå­—ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56656f1-dd75-4c97-8244-88bc521a5608",
   "metadata": {},
   "source": [
    "### 3ï¼‰ä½¿ç”¨å¤–éƒ¨æ•°æ®åº“æ”¯æŒçš„çŸ­æœŸè®°å¿†\n",
    "\n",
    "å¦‚æžœä½¿ç”¨ SQLite ä¿å­˜å½“å‰å·¥ä½œçŠ¶æ€ï¼Œå³ä½¿é€€å‡ºç¨‹åºï¼Œä¾ç„¶èƒ½åœ¨ä¸‹æ¬¡è¿›å…¥æ—¶æ¢å¤ä¸Šæ¬¡é€€å‡ºæ—¶çš„çŠ¶æ€ï¼Œæˆ‘ä»¬æ¥æµ‹è¯•è¿™ä¸€ç‚¹ã€‚\n",
    "\n",
    "åœ¨ä½¿ç”¨ SQLite ä½œä¸ºçŸ­æœŸè®°å¿†çš„å¤–éƒ¨æ•°æ®åº“ä¹‹å‰ï¼Œéœ€è¦å®‰è£…ä¸€ä¸ª Python åŒ…ä»¥æ”¯æŒè¿™é¡¹åŠŸèƒ½ï¼š\n",
    "\n",
    "```bash\n",
    "pip install langgraph-checkpoint-sqlite\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ffbd2f-9330-4663-9547-f21df46af401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ é™¤SQLiteæ•°æ®åº“\n",
    "if os.path.exists(\"short-memory.db\"):\n",
    "    os.remove(\"short-memory.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d3dc0f-dcff-4d2d-b708-8acb516cb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Luochang! It's great to meet you. How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# åŠ è½½æ¨¡åž‹é…ç½®\n",
    "_ = load_dotenv()\n",
    "\n",
    "# åŠ è½½æ¨¡åž‹\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# åˆ›å»ºsqliteæ”¯æŒçš„çŸ­æœŸè®°å¿†\n",
    "checkpointer = SqliteSaver(\n",
    "    sqlite3.connect(\"short-memory.db\", check_same_thread=False)\n",
    ")\n",
    "\n",
    "# åˆ›å»ºAgent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "# å‘Šè¯‰æ™ºèƒ½ä½“æˆ‘å« luochang\n",
    "result = agent.invoke(\n",
    "    {'messages': ['hi! i am luochang']},\n",
    "    {\"configurable\": {\"thread_id\": \"3\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f7a61-8974-4f67-ab6f-9fcf755d4c4e",
   "metadata": {},
   "source": [
    "é‡å¯ Jupyter Notebook åŽçœ‹æ™ºèƒ½ä½“èƒ½å¦ä»Ž SQLite ä¸­è¯»å–å…³äºŽæˆ‘åå­—çš„è®°å¿†ã€‚\n",
    "\n",
    "åœ¨ `Kernel` -> `Restart Kernel...` ä¸­é‡å¯æœåŠ¡ã€‚ç„¶åŽè¿è¡Œä»¥ä¸‹ä»£ç ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "768b2abc-6531-4308-a7b0-16dc80eeca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Luochang! It's great to meet you. How can I assist you today? ðŸ˜Š\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Luochang! ðŸ˜Š How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# åŠ è½½æ¨¡åž‹é…ç½®\n",
    "_ = load_dotenv()\n",
    "\n",
    "# åŠ è½½æ¨¡åž‹\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# åˆ›å»ºsqliteæ”¯æŒçš„çŸ­æœŸè®°å¿†\n",
    "checkpointer = SqliteSaver(\n",
    "    sqlite3.connect(\"short-memory.db\", check_same_thread=False)\n",
    ")\n",
    "\n",
    "# åˆ›å»ºAgent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "# è®©æ™ºèƒ½ä½“å›žå¿†æˆ‘çš„åå­—\n",
    "result = agent.invoke(\n",
    "    {'messages': ['What is my name?']},\n",
    "    {\"configurable\": {\"thread_id\": \"3\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf7455a-da1f-467a-8969-9fd280f35927",
   "metadata": {},
   "source": [
    "## äºŒã€é•¿æœŸè®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45f7cefb-5eb9-4315-be82-b098041832f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from dataclasses import dataclass\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-v4\"\n",
    "EMBED_DIM = 1024\n",
    "\n",
    "# åŠ è½½æ¨¡åž‹é…ç½®\n",
    "_ = load_dotenv()\n",
    "\n",
    "# ç”¨äºŽèŽ·å–text embeddingçš„æŽ¥å£\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    ")\n",
    "\n",
    "# åŠ è½½æ¨¡åž‹\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7474fde3-0f84-4a52-bcd8-46c626208e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddingç”Ÿæˆå‡½æ•°\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "    response = client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=texts,\n",
    "        dimensions=EMBED_DIM,\n",
    "    )\n",
    "\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "# æµ‹è¯•èƒ½å¦æ­£å¸¸ç”Ÿæˆtext embedding\n",
    "texts = [\n",
    "    \"LangGraphçš„ä¸­é—´ä»¶éžå¸¸å¼ºå¤§\",\n",
    "    \"LangGraphçš„MCPä¹Ÿå¾ˆå¥½ç”¨\",\n",
    "]\n",
    "vectors = embed(texts)\n",
    "\n",
    "len(vectors), len(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf724b-0087-41fb-824b-4f7613618871",
   "metadata": {},
   "source": [
    "### 1ï¼‰ç›´æŽ¥è¯»å†™é•¿æœŸè®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cd1e8f5-9d37-4c62-9060-f801912e1948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['users'], key='user_1', value={'rules': ['User likes short, direct language', 'User only speaks English & python'], 'rule_id': '3'}, created_at='2025-11-04T10:08:24.319215+00:00', updated_at='2025-11-04T10:08:24.319226+00:00', score=0.4085710154661828)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.\n",
    "store = InMemoryStore(index={\"embed\": embed, \"dims\": EMBED_DIM})\n",
    "\n",
    "# æ·»åŠ ä¸¤æ¡ç”¨æˆ·æ•°æ®\n",
    "namespace = (\"users\", )\n",
    "key = \"user_1\"\n",
    "store.put(\n",
    "    namespace,\n",
    "    key,\n",
    "    {\n",
    "        \"rules\": [\n",
    "            \"User likes short, direct language\",\n",
    "            \"User only speaks English & python\",\n",
    "        ],\n",
    "        \"rule_id\": \"3\",\n",
    "    },\n",
    ")\n",
    "\n",
    "store.put( \n",
    "    (\"users\",),  # Namespace to group related data together (users namespace for user data)\n",
    "    \"user_2\",  # Key within the namespace (user ID as key)\n",
    "    {\n",
    "        \"name\": \"John Smith\",\n",
    "        \"language\": \"English\",\n",
    "    }  # Data to store for the given user\n",
    ")\n",
    "\n",
    "# get the \"memory\" by ID\n",
    "item = store.get(namespace, \"a-memory\") \n",
    "\n",
    "# search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity\n",
    "items = store.search( \n",
    "    namespace, filter={\"rule_id\": \"3\"}, query=\"language preferences\"\n",
    ")\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908fd8e-e04b-41f6-ba2d-61449d219d81",
   "metadata": {},
   "source": [
    "### 2ï¼‰ä½¿ç”¨å·¥å…·è¯»å–é•¿æœŸè®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd5f5405-5e7f-4d01-a77d-f5c5e30e54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "look up user information\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_user_info (call_fb3ff8f64e7f4bd1b7e2d854)\n",
      " Call ID: call_fb3ff8f64e7f4bd1b7e2d854\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_user_info\n",
      "\n",
      "{'name': 'John Smith', 'language': 'English'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The user's name is John Smith and their language is English.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_info(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    # Access the store - same as that provided to `create_agent`\n",
    "    store = runtime.store \n",
    "    user_id = runtime.context.user_id\n",
    "    # Retrieve data from store - returns StoreValue object with value and metadata\n",
    "    user_info = store.get((\"users\",), user_id) \n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    # Pass store to agent - enables agent to access store when running tools\n",
    "    store=store, \n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"look up user information\"}]},\n",
    "    context=Context(user_id=\"user_2\") \n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0d880-2ece-429a-b4c0-a93de51e70da",
   "metadata": {},
   "source": [
    "### 3ï¼‰ä½¿ç”¨å·¥å…·å†™å…¥é•¿æœŸè®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23fce454-a575-412e-a31c-b196731e6539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Smith'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production.\n",
    "store = InMemoryStore() \n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "# TypedDict defines the structure of user information for the LLM\n",
    "class UserInfo(TypedDict):\n",
    "    name: str\n",
    "\n",
    "# Tool that allows agent to update user information (useful for chat applications)\n",
    "@tool\n",
    "def save_user_info(user_info: UserInfo, runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Save user info.\"\"\"\n",
    "    # Access the store - same as that provided to `create_agent`\n",
    "    store = runtime.store \n",
    "    user_id = runtime.context.user_id \n",
    "    # Store data in the store (namespace, key, data)\n",
    "    store.put((\"users\",), user_id, user_info) \n",
    "    return \"Successfully saved user info.\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_user_info],\n",
    "    store=store,\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is John Smith\"}]},\n",
    "    # user_id passed in context to identify whose information is being updated\n",
    "    context=Context(user_id=\"user_123\") \n",
    ")\n",
    "\n",
    "# You can access the store directly to get the value\n",
    "store.get((\"users\",), \"user_123\").value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4bfc1-bec6-43ee-9f5d-0130f98b2ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dive-into-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
