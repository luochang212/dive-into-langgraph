{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22142d03-67ac-4dab-ba27-9f22690244d5",
   "metadata": {},
   "source": [
    "# 上下文工程\n",
    "\n",
    "[上下文工程](https://docs.langchain.com/oss/python/langchain/context-engineering)（Context Engineering）对于 Agent 得出正确的结果至关重要。模型回答不好，很多时候不是因为能力不足，而是因为没有获得足以推断出正确结果的上下文信息。通过上下文工程，增强 Agent 获取和管理上下文的能力，是很有必要的。\n",
    "\n",
    "**LangGraph 将上下文分为三种类型：**\n",
    "\n",
    "- 模型上下文（Model Context）\n",
    "- 工具上下文（Tool Context）\n",
    "- 生命周期上下文（Life-cycle Context）\n",
    "\n",
    "无论哪种 Context，都需要定义它的 Schema。在这方面，LangGraph 提供了相当高的自由度，你可以使用 `dataclasses`、`pydantic`、`TypedDict` 这些包的任意一个创建你的 Context Schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4412b776-1f74-41e8-9444-f1724bcff581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipynbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a92bc3-bd5e-4ad9-8b4a-2ae1d0f171cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import sqlite3\n",
    "\n",
    "from typing import Callable\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, wrap_model_call, ModelRequest, ModelResponse, SummarizationMiddleware\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.sqlite import SqliteStore\n",
    "\n",
    "# 加载模型配置\n",
    "_ = load_dotenv()\n",
    "\n",
    "# 加载模型\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f5631-a9f6-40d5-9e57-d652e347c993",
   "metadata": {},
   "source": [
    "## 一、动态修改系统提示词\n",
    "\n",
    "上下文工程与前序章节的中间件（middleware）和记忆（memory）密不可分。上下文的具体实现依赖中间件，而上下文的存储则依赖记忆系统。具体来讲，LangGraph 预置了 `@dynamic_prompt` 中间件，用于动态修改系统提示词。\n",
    "\n",
    "既然是动态修改，肯定需要某个条件来触发修改。除了开发触发逻辑，我们还需要从智能体中获取触发逻辑所需的即时变量。这些变量通常存储在以下三个存储介质中：\n",
    "\n",
    "- 运行时（Runtime）- 所有节点共享一个 Runtime。同一时刻，所有节点取到的 Runtime 的值是相同的。一般用于存储时效性要求较高的信息。\n",
    "- 短期记忆（State）- 在节点之间按顺序传递，每个节点接收上一个节点处理后的 State。主要用于存储 Prompt 和 AI Message。\n",
    "- 长期记忆（Store）- 负责持久化存储，可以跨 Workflow / Agent 保存信息。可以用来存用户偏好、以前算过的统计值等。\n",
    "\n",
    "以下三个例子，分别演示如何使用来自 Runtime、State、Store 中的上下文，编写触发条件。\n",
    "\n",
    "### 1）使用 `State` 加载上下文\n",
    "\n",
    "利用 `State` 中蕴含的信息操纵 system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a9eb1bf-37b9-4aab-a8f3-0e1cffca6eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n",
      "This is a long conversation - be extra concise.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "广州今天的天气怎么样？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "广州天气很好\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "吃点什么好呢\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "要不要吃香茅鳗鱼煲\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "香茅是什么\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "香茅又名柠檬草，常见于泰式冬阴功汤、越南烤肉\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "auv 那还等什么，咱吃去吧\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "那走吧，正好去尝尝地道的香茅鳗鱼煲！\n"
     ]
    }
   ],
   "source": [
    "@dynamic_prompt\n",
    "def state_aware_prompt(request: ModelRequest) -> str:\n",
    "    # request.messages is a shortcut for request.state[\"messages\"]\n",
    "    message_count = len(request.messages)\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if message_count > 6:\n",
    "        base += \"\\nThis is a long conversation - be extra concise.\"\n",
    "\n",
    "    # 临时打印base看效果\n",
    "    print(base)\n",
    "\n",
    "    return base\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[state_aware_prompt]\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"广州今天的天气怎么样？\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"广州天气很好\"},\n",
    "        {\"role\": \"user\", \"content\": \"吃点什么好呢\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"要不要吃香茅鳗鱼煲\"},\n",
    "        {\"role\": \"user\", \"content\": \"香茅是什么\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"香茅又名柠檬草，常见于泰式冬阴功汤、越南烤肉\"},\n",
    "        {\"role\": \"user\", \"content\": \"auv 那还等什么，咱吃去吧\"},\n",
    "    ]},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c9a5d-90a9-464d-b0dd-bc0b383ce149",
   "metadata": {},
   "source": [
    "把 `message_count > 6` 里的 6 改成 7，试试看会发生什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4c6d6-cea7-448a-ae42-33bcc64b77a3",
   "metadata": {},
   "source": [
    "### 2）使用 `Store` 加载上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e98294b9-7a56-499b-a190-e0181e2d6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def store_aware_prompt(request: ModelRequest) -> str:\n",
    "    user_id = request.runtime.context.user_id\n",
    "\n",
    "    # Read from Store: get user preferences\n",
    "    store = request.runtime.store\n",
    "    user_prefs = store.get((\"preferences\",), user_id)\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_prefs:\n",
    "        style = user_prefs.value.get(\"communication_style\", \"balanced\")\n",
    "        base += f\"\\nUser prefers {style} responses.\"\n",
    "\n",
    "    return base\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[store_aware_prompt],\n",
    "    context_schema=Context,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "# 预置两条偏好信息\n",
    "store.put((\"preferences\",), \"user_1\", {\"communication_style\": \"Chinese\"})\n",
    "store.put((\"preferences\",), \"user_2\", {\"communication_style\": \"Korean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509b7bc4-1a3b-4b32-9afe-3db4894c1ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant. Please be extra concise.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is a \"hold short line\"?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "“Hold short line” 是航空术语，指飞机在跑道上等待起飞时应停在的标记线，通常位于跑道起始端的某个位置，用于确保飞机在起飞前保持适当的安全距离。\n"
     ]
    }
   ],
   "source": [
    "# 用户1喜欢中文回复\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please be extra concise.\"},\n",
    "        {\"role\": \"user\", \"content\": 'What is a \"hold short line\"?'}\n",
    "    ]},\n",
    "    context=Context(user_id=\"user_1\"),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288d2a65-b328-4448-a155-222afc84f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant. Please be extra concise.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is a \"hold short line\"?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\"_hold short line_\"은 항공 분야에서 사용되는 용어로, 특정 지점에 비행기가 멈춰 있을 수 있도록 지정된 선을 의미합니다. 일반적으로 이선은 활주로의 끝 부분과 이륙 지점 사이에 위치하며, 항공기의 이륙 준비 상태를 나타냅니다.\n"
     ]
    }
   ],
   "source": [
    "# 用户2喜欢韩文回复\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please be extra concise.\"},\n",
    "        {\"role\": \"user\", \"content\": 'What is a \"hold short line\"?'}\n",
    "    ]},\n",
    "    context=Context(user_id=\"user_2\"),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea07a9a-289f-4f4c-987c-a76f4818e753",
   "metadata": {},
   "source": [
    "### 3）使用 `Runtime` 加载上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8776b008-b2a7-4947-8bed-f51460d37712",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    user_role: str\n",
    "    deployment_env: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def context_aware_prompt(request: ModelRequest) -> str:\n",
    "    # Read from Runtime Context: user role and environment\n",
    "    user_role = request.runtime.context.user_role\n",
    "    env = request.runtime.context.deployment_env\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_role == \"admin\":\n",
    "        base += \"\\nYou can use the get_weather tool.\"\n",
    "    else:\n",
    "        base += \"\\nYou are prohibited from using the get_weather tool.\"\n",
    "\n",
    "    if env == \"production\":\n",
    "        base += \"\\nBe extra careful with any data modifications.\"\n",
    "\n",
    "    return base\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    middleware=[context_aware_prompt],\n",
    "    context_schema=Context,\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db1a91c1-f87f-46ce-b6fe-251040867390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "广州今天的天气怎么样？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (019ac8e704e6df19d3769b303f7e390e)\n",
      " Call ID: 019ac8e704e6df19d3769b303f7e390e\n",
      "  Args:\n",
      "    city: 广州\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's always sunny in 广州!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "广州今天天气晴朗，阳光明媚！记得做好防晒哦！\n"
     ]
    }
   ],
   "source": [
    "# 利用 Runtime 中的两个变量，动态控制 System prompt\n",
    "# 将 user_role 设为 admin，允许使用天气查询工具\n",
    "config = {'configurable': {'thread_id': str(uuid.uuid4())}}\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"广州今天的天气怎么样？\"}]},\n",
    "    context=Context(user_role=\"admin\", deployment_env=\"production\"),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d51ba924-4b11-4268-a498-29104a3916bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "广州今天的天气怎么样？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (019ac8e718f72c910f14732491e266e7)\n",
      " Call ID: 019ac8e718f72c910f14732491e266e7\n",
      "  Args:\n",
      "    city: 广州\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's always sunny in 广州!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "广州今天天气晴朗，阳光明媚，是个非常适合外出的好日子！记得做好防晒措施哦。\n"
     ]
    }
   ],
   "source": [
    "# 若将 user_role 改为 viewer，则无法使用天气查询工具\n",
    "config = {'configurable': {'thread_id': str(uuid.uuid4())}}\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"广州今天的天气怎么样？\"}]},\n",
    "    context=Context(user_role=\"viewer\", deployment_env=\"production\"),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ae08b79-0e58-4d4a-90c9-22e9624a4a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='广州今天的天气怎么样？', additional_kwargs={}, response_metadata={}, id='d52217de-4940-45fa-bbfb-e8bb89a94e13'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 183, 'total_tokens': 202, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '019ac8e712900596018ffade98d5e806', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--5117421b-c3f6-4750-9ec4-26b8141ba8d4-0', tool_calls=[{'name': 'get_weather', 'args': {'city': '广州'}, 'id': '019ac8e718f72c910f14732491e266e7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 183, 'output_tokens': 19, 'total_tokens': 202, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}}),\n",
       " ToolMessage(content=\"It's always sunny in 广州!\", name='get_weather', id='4958a652-c53e-4b55-9352-5a6806c1a934', tool_call_id='019ac8e718f72c910f14732491e266e7'),\n",
       " AIMessage(content='广州今天天气晴朗，阳光明媚，是个非常适合外出的好日子！记得做好防晒措施哦。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 224, 'total_tokens': 245, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '019ac8e71a0848f0a3622b04434d0103', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--98c4a04e-7db3-4842-8d00-cdc6e0aaa7ad-0', usage_metadata={'input_tokens': 224, 'output_tokens': 21, 'total_tokens': 245, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e6d02-152c-4a13-a5fc-60e27113d596",
   "metadata": {},
   "source": [
    "## 二、动态修改消息列表\n",
    "\n",
    "LangGraph 预制了动态修改消息列表（Messages）的中间件 `@wrap_model_call`。上一节已经演示如何从 `State`、`Store`、`Runtime` 中获取上下文，本节将不再一一演示。在下面这个例子中，我们主要演示如何使用 `Runtime` 将本地文件的内容注入消息列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc7b4e4a-1dca-4e40-bafa-840373986c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FileContext:\n",
    "    uploaded_files: list[dict]\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_file_context(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"Inject context about files user has uploaded this session.\"\"\"\n",
    "    uploaded_files = request.runtime.context.uploaded_files\n",
    "\n",
    "    try:\n",
    "        base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except Exception as e:\n",
    "        import ipynbname\n",
    "        import os\n",
    "        notebook_path = ipynbname.path()\n",
    "        base_dir = os.path.dirname(notebook_path)\n",
    "\n",
    "    file_sections = []\n",
    "    for file in uploaded_files:\n",
    "        name, ftype = \"\", \"\"\n",
    "        path = file.get(\"path\")\n",
    "        if path:\n",
    "            base_filename = os.path.basename(path)\n",
    "            stem, ext = os.path.splitext(base_filename)\n",
    "            name = stem or base_filename\n",
    "            ftype = (ext.lstrip(\".\") if ext else None)\n",
    "\n",
    "            # 构建文件描述内容\n",
    "            content_list = [f\"名称: {name}\"]\n",
    "            if ftype:\n",
    "                content_list.append(f\"类型: {ftype}\")\n",
    "\n",
    "            # 解析相对路径为绝对路径\n",
    "            abs_path = path if os.path.isabs(path) else os.path.join(base_dir, path)\n",
    "\n",
    "            # 读取文件内容\n",
    "            content_block = \"\"\n",
    "            if abs_path and os.path.exists(abs_path):\n",
    "                try:\n",
    "                    with open(abs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        content_block = f.read()\n",
    "                except Exception as e:\n",
    "                    content_block = f\"[读取文件错误 '{abs_path}': {e}]\"\n",
    "            else:\n",
    "                content_block = \"[文件路径缺失或未找到]\"\n",
    "\n",
    "            section = (\n",
    "                f\"---\\n\"\n",
    "                f\"{chr(10).join(content_list)}\\n\\n\"\n",
    "                f\"{content_block}\\n\"\n",
    "                f\"---\"\n",
    "            )\n",
    "            file_sections.append(section)\n",
    "\n",
    "        file_context = (\n",
    "            \"已加载的会话文件：\\n\"\n",
    "            f\"{chr(10).join(file_sections)}\"\n",
    "            \"\\n回答问题时请参考这些文件。\"\n",
    "        )\n",
    "\n",
    "        # Inject file context before recent messages\n",
    "        messages = [  \n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": file_context},\n",
    "        ]\n",
    "        request = request.override(messages=messages)  \n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[inject_file_context],\n",
    "    context_schema=FileContext,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9048a7e0-2131-4841-82f2-b1f7fca1c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "关于上海地铁的无脸乘客，有什么需要注意的？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "欢迎来到上海的夜色中。关于“无脸乘客”，请务必牢记以下注意事项：\n",
      "\n",
      "**1. 地铁运营结束后的警惕：**\n",
      "- 上海地铁通常在深夜23:00左右停止运营，若你未能及时下车，且仍在车厢内，可能会遇到一位无脸乘客。\n",
      "- 他会出现并低声问你：“你要去哪？”\n",
      "- **请务必报出一个真实存在的上海地名**，例如“人民广场”、“陆家嘴”、“徐家汇”等。\n",
      "- **切勿说出不存在的地名**，也切勿保持沉默，否则你可能会在车厢内看到自己的尸体。\n",
      "\n",
      "**2. 与无脸乘客互动的禁忌：**\n",
      "- 无脸乘客不会说话，也不会有面部表情，他的存在是无形的。\n",
      "- **即使他问你问题，也请不要试图与他交流**，更不要试图看清他的脸。\n",
      "- **回答时要简短、明确，只说出一个地名**，并迅速离开车厢。\n",
      "\n",
      "**3. 保持冷静与理智：**\n",
      "- 无脸乘客的出现可能是某种超自然现象，也可能是心理暗示或幻觉。\n",
      "- 如果你感到不安或怀疑，**请立即离开地铁站，不要继续留在车厢内**。\n",
      "- **不要相信任何与无脸乘客有关的异常现象**，比如他试图引导你去某个地方、或对你做出其他异常举动。\n",
      "\n",
      "**4. 提高安全意识：**\n",
      "- 如果你已经离开地铁站，但仍然感到不安，建议你**不要独自在深夜外出**，尤其是前往偏僻或人烟稀少的区域。\n",
      "- 保持手机电量充足，随时可以联系他人或寻求帮助。\n",
      "\n",
      "**5. 信任自己的直觉：**\n",
      "- 如果你感觉无脸乘客是危险的，**请相信自己的直觉，迅速离开现场**。\n",
      "- 无脸乘客可能只是传说，但在某些文化背景下，它被认为是一种警示或禁忌。\n",
      "\n",
      "总之，在上海的深夜地铁中，遇到无脸乘客时，**保持冷静、理智，遵守规则，是保护自己的关键**。希望你在夜色中平安无事。\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"关于上海地铁的无脸乘客，有什么需要注意的？\",\n",
    "        }],\n",
    "    },\n",
    "    context=FileContext(uploaded_files=[{\"path\": \"./docs/rule_horror.md\"}]),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59498b8d-9b5d-4cb3-bc86-0230e76a8121",
   "metadata": {},
   "source": [
    "## 三、在工具中使用上下文\n",
    "\n",
    "下面，我们尝试在工具中使用存储在 `SqliteStore` 中的上下文信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a33e3357-71e3-4ae3-a956-9e6ad0076a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 删除SQLite数据库\n",
    "if os.path.exists(\"user-info.db\"):\n",
    "    os.remove(\"user-info.db\")\n",
    "\n",
    "# 创建SQLite存储\n",
    "conn = sqlite3.connect(\"user-info.db\", check_same_thread=False, isolation_level=None)\n",
    "conn.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "conn.execute(\"PRAGMA busy_timeout = 30000;\")\n",
    "\n",
    "store = SqliteStore(conn)\n",
    "\n",
    "print(store.search(\"user_info\"))\n",
    "\n",
    "# 预置两条用户信息\n",
    "store.put((\"user_info\",), \"柳如烟\", {\"description\": \"清冷才女，身怀绝技，为寻身世之谜踏入江湖。\", \"birthplace\": \"吴兴县\"})\n",
    "store.put((\"user_info\",), \"苏慕白\", {\"description\": \"孤傲剑客，剑法超群，背负家族血仇，隐于市井追寻真相。\", \"birthplace\": \"杭县\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dd8c15-f80a-4885-9477-37d84bbf9495",
   "metadata": {},
   "source": [
    "### 1）基础用例\n",
    "\n",
    "使用 `ToolRuntime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de7547ce-963e-48bf-9855-ab32521c034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fetch_user_data(\n",
    "    user_id: str,\n",
    "    runtime: ToolRuntime\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Fetch user information from the in-memory store.\n",
    "\n",
    "    :param user_id: The unique identifier of the user.\n",
    "    :param runtime: The tool runtime context injected by the framework.\n",
    "    :return: The user's description string if found; an empty string otherwise.\n",
    "    \"\"\"\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"user_info\",), user_id)\n",
    "\n",
    "    user_desc = \"\"\n",
    "    if user_info:\n",
    "        user_desc = user_info.value.get(\"description\", \"\")\n",
    "\n",
    "    return user_desc\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[fetch_user_data],\n",
    "    store=store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60289d99-0235-464c-837c-407065b0096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "五分钟之内，我要柳如烟的全部信息\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_user_data (019ac8f01f1db1b9fbf6f85c8b49fc93)\n",
      " Call ID: 019ac8f01f1db1b9fbf6f85c8b49fc93\n",
      "  Args:\n",
      "    user_id: 柳如烟\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_user_data\n",
      "\n",
      "清冷才女，身怀绝技，为寻身世之谜踏入江湖。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "柳如烟是一位清冷才女，身怀绝技，性格孤傲，行事果断。她因追寻自己的身世之谜而踏入江湖，历经种种磨难与挑战，逐渐揭开身世背后的秘密。在江湖中，她以智慧和武艺著称，常常以一个旁观者的姿态观察世事，却在关键时刻挺身而出，为正义而战。她的故事充满了悬疑与冒险，令人回味无穷。\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"五分钟之内，我要柳如烟的全部信息\"\n",
    "    }]\n",
    "})\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620c05d-aa96-4d3b-9dfd-9774c99e38f7",
   "metadata": {},
   "source": [
    "### 2）复杂一点的例子\n",
    "\n",
    "使用 `ToolRuntime[Context]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1950ba66-93e9-43d2-af5b-b048783287bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    key: str\n",
    "\n",
    "@tool\n",
    "def fetch_user_data(\n",
    "    user_id: str,\n",
    "    runtime: ToolRuntime[Context]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Fetch user information from the in-memory store.\n",
    "\n",
    "    :param user_id: The unique identifier of the user.\n",
    "    :param runtime: The tool runtime context injected by the framework.\n",
    "    :return: The user's description string if found; an empty string otherwise.\n",
    "    \"\"\"\n",
    "    key = runtime.context.key\n",
    "\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"user_info\",), user_id)\n",
    "\n",
    "    user_desc = \"\"\n",
    "    if user_info:\n",
    "        user_desc = user_info.value.get(key, \"\")\n",
    "\n",
    "    return f\"{key}: {user_desc}\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[fetch_user_data],\n",
    "    store=store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dd427af-d129-401c-a643-eea926af05d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "五分钟之内，我要柳如烟的全部信息\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_user_data (019ac8f0733ffa7402952cad57c67139)\n",
      " Call ID: 019ac8f0733ffa7402952cad57c67139\n",
      "  Args:\n",
      "    user_id: 柳如烟\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_user_data\n",
      "\n",
      "birthplace: 吴兴县\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "柳如烟的出生地是吴兴县。如果您需要更多关于她的信息，请进一步说明。\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"五分钟之内，我要柳如烟的全部信息\"}]},\n",
    "    context=Context(key=\"birthplace\"),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a892c0-3a74-47d4-aef2-dd7bf3270ead",
   "metadata": {},
   "source": [
    "### 四、压缩上下文\n",
    "\n",
    "LangChain 提供了内置的中间件 `SummarizationMiddleware` 用于压缩上下文。该中间件维护的是典型的 **生命周期上下文**，与 **模型上下文** 和 **工具上下文** 的瞬态更新不同，生命周期上下文会持续更新：持续将旧消息替换为摘要。\n",
    "\n",
    "除非上下文超长，导致模型能力降低，否则不需要使用 `SummarizationMiddleware`。一般来说，触发摘要得值可以设得较大。比如：\n",
    "\n",
    "- `max_tokens_before_summary`: 3000\n",
    "- `messages_to_keep`: 20\n",
    "\n",
    "> 如果你想了解更多关于上下文腐坏（Context Rot）的信息，Chroma 团队在 2025 年 7 月 14 日发布的 [*Context Rot: How Increasing Input Tokens Impacts LLM Performance*](https://research.trychroma.com/context-rot)，系统性地揭示了长上下文导致模型性能退化的现象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c75a7d59-9edf-4a00-af8a-3a6d06d6f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建短期记忆\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# 创建带内置摘要中间件的Agent\n",
    "# 为了让配置能在我们的例子里生效，这里的触发值设得很小\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=llm,\n",
    "            trigger=('tokens', 40),  # Trigger summarization at 40 tokens\n",
    "            keep=(\"messages\",1),  # Keep last 1 messages after summary\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91068064-ef38-4ae3-841b-5bc7be34c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Here is a summary of the conversation to date:\n",
      "\n",
      "广州今天的天气很好。香茅又名柠檬草，常见于泰式冬阴功汤、越南烤肉。\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "auv 那还等什么，咱吃去吧\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "哈哈，你说得对！广州天气这么好，正好是出门吃美食的好时机。香茅作为泰式冬阴功汤和越南烤肉的常见香料，它的清新香气真的能让食物更上一层楼。要不要一起去尝尝地道的泰式冬阴功或者越南烤肉？我可以推荐一些当地不错的餐馆哦！\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"广州今天的天气怎么样？\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"广州天气很好\"},\n",
    "        {\"role\": \"user\", \"content\": \"吃点什么好呢\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"要不要吃香茅鳗鱼煲\"},\n",
    "        {\"role\": \"user\", \"content\": \"香茅是什么\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"香茅又名柠檬草，常见于泰式冬阴功汤、越南烤肉\"},\n",
    "        {\"role\": \"user\", \"content\": \"auv 那还等什么，咱吃去吧\"},\n",
    "    ]},\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725262df-d313-4499-ad09-fe12ac9c7955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dive-into-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
