{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da96a78-5bcd-4ea3-b5cc-addb660a1554",
   "metadata": {},
   "source": [
    "# ä¸­é—´ä»¶\n",
    "\n",
    "[ä¸­é—´ä»¶](https://docs.langchain.com/oss/python/langchain/middleware/overview)ï¼ˆmiddlewareï¼‰æ˜¯æœ¬æ¬¡æ›´æ–°ä¸­æœ€äº®çœ¼çš„ç‰¹æ€§ï¼Œè¯¸å¤šæ–°åŠŸèƒ½å‡è—‰ç”±ä¸­é—´ä»¶å®ç°ï¼Œæ¯”å¦‚äººæœºäº¤äº’ã€åŠ¨æ€ç³»ç»Ÿæç¤ºè¯ã€åŠ¨æ€æ³¨å…¥ä¸Šä¸‹æ–‡ç­‰ç­‰ã€‚ä¸­é—´ä»¶æ˜¯ä¸€ç§é’©å­å‡½æ•°ã€‚é€šè¿‡å‘å·¥ä½œæµä¸­é¢„åŸ‹ä¸­é—´ä»¶ï¼Œèƒ½å¤Ÿå®ç°å·¥ä½œæµçš„é«˜æ•ˆæ‹“å±•å’Œå¯å®šåˆ¶åŒ–ã€‚\n",
    "\n",
    "LangChain é€šè¿‡ [è£…é¥°å™¨](https://reference.langchain.com/python/langchain/middleware/#decorators) åˆ›å»º **è‡ªå®šä¹‰ä¸­é—´ä»¶**ã€‚\n",
    "\n",
    "```{dropdown} è£…é¥°å™¨ç±»å‹ï¼ˆç‚¹å‡»å±•å¼€ï¼‰\n",
    "\n",
    "  | DECORATOR | DESCRIPTION |\n",
    "  | -- | -- |\n",
    "  | `@before_agent` | åœ¨ Agent æ‰§è¡Œå‰æ‰§è¡Œé€»è¾‘ |\n",
    "  | `@after_agent` | åœ¨ Agent æ‰§è¡Œåæ‰§è¡Œé€»è¾‘ |\n",
    "  | `@before_model` | åœ¨æ¯æ¬¡æ¨¡å‹è°ƒç”¨å‰æ‰§è¡Œé€»è¾‘ |\n",
    "  | `@after_model` | åœ¨æ¯æ¬¡æ¨¡å‹æ”¶åˆ°å“åº”åæ‰§è¡Œé€»è¾‘ |\n",
    "  | `@wrap_model_call` | æ§åˆ¶æ¨¡å‹çš„è°ƒç”¨è¿‡ç¨‹ |\n",
    "  | `@wrap_tool_call` | æ§åˆ¶å·¥å…·çš„è°ƒç”¨è¿‡ç¨‹ |\n",
    "  | `@dynamic_prompt` | åŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ |\n",
    "  | `@hook_config` | é…ç½®é’©å­è¡Œä¸º |\n",
    "\n",
    "```\n",
    "\n",
    "**è£…é¥°å™¨ç±»å‹** å†³å®šä¸­é—´ä»¶çš„æ‰§è¡Œä½ç½®ã€‚æ¯”å¦‚ä½¿ç”¨ `@before_model` è£…é¥°å™¨ï¼Œèƒ½å¤Ÿåœ¨æ¨¡å‹è°ƒç”¨å‰æ‰§è¡Œç‰¹å®šé€»è¾‘ã€‚**è¢«è£…é¥°å‡½æ•°** è´Ÿè´£è¿™æ®µç‰¹å®šé€»è¾‘çš„å…·ä½“å®ç°ã€‚è¿™ä¹ˆè¯´å¯èƒ½æœ‰ç‚¹æŠ½è±¡ã€‚æ²¡å…³ç³»ï¼Œæœ¬èŠ‚æä¾›äº†å››ä¸ªä¾‹å­ï¼Œçœ‹å®Œä½ ä¸€å®šèƒ½å¤Ÿé¢†æ‚Ÿåˆ°ä¸­é—´ä»¶çš„ä½¿ç”¨æ–¹æ³•ï¼š\n",
    "\n",
    "- é¢„ç®—æ§åˆ¶\n",
    "- æ¶ˆæ¯æˆªæ–­\n",
    "- æ•æ„Ÿè¯è¿‡æ»¤\n",
    "- PII æ£€æµ‹`ï¼ˆä¸ªäººéšç§ä¿¡æ¯æ£€æµ‹ï¼‰`\n",
    "\n",
    "## ä¸€ã€é¢„ç®—æ§åˆ¶\n",
    "\n",
    "éšç€å¯¹è¯è½®æ¬¡å¢åŠ ï¼Œå¯¹è¯è®°å½•ä¹Ÿè¶Šæ¥è¶Šé•¿ï¼Œä»è€Œå¯¼è‡´è¯·æ±‚è´¹ç”¨ä¸Šå‡ã€‚ä¸ºäº†æ§åˆ¶é¢„ç®—ï¼Œå¯ä»¥è®¾å®šåœ¨å¯¹è¯è½®æ¬¡è¶…è¿‡æŸä¸ªé˜ˆå€¼åï¼Œåˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ã€‚ä¸‹é¢æˆ‘ä»¬ç”¨è‡ªå®šä¹‰ä¸­é—´ä»¶å®ç°è¿™ä¸ªåŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd14ba5-4b0c-4cfb-a976-040d0a365f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.messages import HumanMessage\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# åŠ è½½æ¨¡å‹é…ç½®\n",
    "_ = load_dotenv()\n",
    "\n",
    "# ä½è´¹ç‡æ¨¡å‹\n",
    "basic_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    ")\n",
    "\n",
    "# é«˜è´¹ç‡æ¨¡å‹\n",
    "advanced_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4033cbf-b59f-4a6b-9fd1-f102b7fea252",
   "metadata": {},
   "source": [
    "ç”±äºæˆ‘ä»¬çš„ä¿®æ”¹æ¶‰åŠæ¨¡å‹æ¨ç†ï¼Œ`@before_model` å’Œ `@after_model` åœ¨è¿™é‡Œå·²ç»ä¸å¤Ÿç”¨äº†ã€‚æˆ‘ä»¬é€‰ç”¨å¯ä»¥å¹²æ¶‰æ¨¡å‹è°ƒç”¨çš„ [`@wrap_model_call`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_model_call) è£…é¥°å™¨ã€‚å…·ä½“é€»è¾‘ç”±å‡½æ•° `dynamic_model_selection` å®ç°ï¼šå½“å†å²å¯¹è¯è¶…è¿‡ 5 æ¡æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e758792-47d8-4ea4-857e-dddbbc71eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 5:\n",
    "        # Use a basic model for longer conversations\n",
    "        model = basic_model\n",
    "    else:\n",
    "        model = advanced_model\n",
    "\n",
    "    print(f\"message_count: {message_count}\")\n",
    "    print(f\"model_name: {model.model_name}\")\n",
    "\n",
    "    return handler(request.override(model=model))\n",
    "\n",
    "agent = create_agent(\n",
    "    model=advanced_model,  # Default model\n",
    "    middleware=[dynamic_model_selection]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850013a4",
   "metadata": {},
   "source": [
    "ä»ä¸‹é¢çš„ä¾‹å­å¯ä»¥çœ‹å‡ºï¼Œå½“å†å²å¯¹è¯æ•° `message_count` è¶…è¿‡ 5 æ¡æ—¶ï¼Œç¡®å®ä»é«˜è´¹ç‡æ¨¡å‹ `qwen3-max` åˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ `qwen3-coder-plus`ã€‚æˆ‘ä»¬æˆåŠŸå®ç°äº†é¢„ç®—æ§åˆ¶åŠŸèƒ½ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b4ed25-2ef8-4a24-9760-89f1ed34bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 ===\n",
      "message_count: 1\n",
      "model_name: qwen3-max\n",
      "content: æ™®é€šæ±½è½¦é€šå¸¸æœ‰4ä¸ªè½®å­ã€‚\n",
      "\n",
      "=== Round 2 ===\n",
      "message_count: 3\n",
      "model_name: qwen3-max\n",
      "content: é£æœºçš„è½®å­æ•°é‡å› æœºå‹è€Œå¼‚ï¼Œå¸¸è§çš„å®¢æœºä¸€èˆ¬æœ‰3ä¸ªèµ·è½æ¶ï¼ˆå‰1ä¸ªã€ä¸»èµ·è½æ¶2ä¸ªï¼‰ï¼Œæ€»å…±6åˆ°10ä¸ªè½®å­ã€‚ä¾‹å¦‚ï¼Œæ³¢éŸ³737æœ‰6ä¸ªè½®å­ï¼Œè€Œå¤§å‹å®¢æœºå¦‚ç©ºå®¢A380æœ‰22ä¸ªè½®å­ã€‚\n",
      "\n",
      "=== Round 3 ===\n",
      "message_count: 5\n",
      "model_name: qwen3-max\n",
      "content: æ‘©æ‰˜è½¦é€šå¸¸æœ‰2ä¸ªè½®å­ã€‚\n",
      "\n",
      "=== Round 4 ===\n",
      "message_count: 7\n",
      "model_name: qwen3-coder-plus\n",
      "content: è‡ªè¡Œè½¦æœ‰2ä¸ªè½®å­ã€‚\n"
     ]
    }
   ],
   "source": [
    "state: MessagesState = {\"messages\": []}\n",
    "items = ['æ±½è½¦', 'é£æœº', 'æ‘©æ‰˜è½¦', 'è‡ªè¡Œè½¦']\n",
    "for idx, i in enumerate(items):\n",
    "    print(f\"\\n=== Round {idx+1} ===\")\n",
    "    state[\"messages\"] += [HumanMessage(content=f\"{i}æœ‰å‡ ä¸ªè½®å­ï¼Œè¯·ç®€å•å›ç­”\")]\n",
    "    result = agent.invoke(state)\n",
    "    state[\"messages\"] = result[\"messages\"]\n",
    "    print(f'content: {result[\"messages\"][-1].content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc58247-324d-40fe-83e5-b34f9ec564e6",
   "metadata": {},
   "source": [
    "## äºŒã€æ¶ˆæ¯æˆªæ–­\n",
    "\n",
    "LLM çš„ä¸Šä¸‹æ–‡å­˜åœ¨é•¿åº¦é™åˆ¶ã€‚ä¸€æ—¦è¶…è¿‡é™åˆ¶ï¼Œå°±éœ€è¦å¯¹ä¸Šä¸‹æ–‡è¿›è¡Œå‹ç¼©ã€‚åœ¨ä¼—å¤šå¤„ç†æ–¹æ¡ˆä¸­ï¼Œæ¶ˆæ¯æˆªæ–­æ˜¯æœ€ç®€å•çš„ã€‚ä¸‹é¢æˆ‘ä»¬é€šè¿‡ `@before_model` è£…é¥°å™¨å®ç°æ¶ˆæ¯æˆªæ–­åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08619c1-6940-4043-be1b-3282be16c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750eee1-a873-424c-878b-61ec5bf81f0e",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°è¯•ä¸€ç§æˆªæ–­ç­–ç•¥ï¼šåœ¨ä¿ç•™æœ€è¿‘æ¶ˆæ¯çš„åŒæ—¶ï¼Œé¢å¤–ä¿ç•™ç¬¬ä¸€æ¡æ¶ˆæ¯ã€‚åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œç”±äºæˆ‘ä»¬åœ¨ç¬¬ä¸€æ¡æ¶ˆæ¯ä¸­å°±å‘Šè¯‰æ™ºèƒ½ä½“ã€Œæˆ‘æ˜¯ bobã€ï¼Œå› æ­¤å®ƒè®°å¾—æˆ‘æ˜¯ bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefc09f4-d67f-4a7a-b930-171043e0a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! You introduced yourself to me earlier.\n"
     ]
    }
   ],
   "source": [
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    basic_model,\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "def agent_invoke(agent):\n",
    "    agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "    agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "    agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "    final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "    \n",
    "    final_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "agent_invoke(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2afa04-18ad-487d-9cef-dfba0b5ec36d",
   "metadata": {},
   "source": [
    "å½“ç„¶ï¼Œè¿™ä¸ªè¡¨ç°ä¸è¶³ä»¥è¯´æ˜æˆªæ–­ä¸­é—´ä»¶çœŸçš„ç”Ÿæ•ˆäº†ã€‚è‹¥è¿™ä¸ªä¸­é—´ä»¶ä»æœªç”Ÿæ•ˆï¼Œä¹Ÿä¼šæœ‰è¿™æ ·çš„ç»“æœã€‚ä¸ºäº†è¯æ˜å®ƒçœŸçš„ç”Ÿæ•ˆäº†ï¼Œæˆ‘ä»¬å†æ¬¡ä¿®æ”¹æˆªæ–­ç­–ç•¥ã€‚è¿™æ¬¡åªä¿ç•™æœ€åä¸¤æ¡å¯¹è¯è®°å½•ã€‚å¦‚æœæ™ºèƒ½ä½“ä¸è®°å¾—æˆ‘æ˜¯ bobï¼Œè¯´æ˜æˆªæ–­ä¸­é—´ä»¶ç¡®å®èµ·ä½œç”¨äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc2a8e62-b7c4-4275-8967-7c551a73c6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have access to your name or personal information. I'm an AI assistant designed to help with questions and tasks, but I don't know who you are specifically. If you'd like to share your name, I'd be happy to use it in our conversation!\n"
     ]
    }
   ],
   "source": [
    "@before_model\n",
    "def trim_without_first_message(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *messages[-2:]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    basic_model,\n",
    "    middleware=[trim_without_first_message],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "agent_invoke(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e989c",
   "metadata": {},
   "source": [
    "ç°åœ¨æ™ºèƒ½ä½“ä¸è®°å¾—æˆ‘æ˜¯è°ï¼Œè¯´æ˜ä¸­é—´ä»¶ç¡®å®ç”Ÿæ•ˆäº†ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1220c4b-13f2-48e0-90d8-3fb2bc92e5bd",
   "metadata": {},
   "source": [
    "## ä¸‰ã€æ•æ„Ÿè¯è¿‡æ»¤\n",
    "\n",
    "**æŠ¤æ **ï¼ˆGuardrailsï¼‰æ˜¯æ™ºèƒ½ä½“æä¾›çš„ä¸€ç±»å†…å®¹å®‰å…¨èƒ½åŠ›çš„ç»Ÿç§°ã€‚å¤§æ¨¡å‹æœ¬èº«å…·å¤‡ä¸€å®šçš„å†…å®¹é£æ§èƒ½åŠ›ï¼Œä½†å¾ˆå®¹æ˜“è¢«çªç ´ã€‚æœç´¢ã€Œå¤§æ¨¡å‹ç ´ç”²ã€å°±èƒ½æ‰¾åˆ°æ­¤ç±»æ•™ç¨‹ã€‚æ™ºèƒ½ä½“å¯ä»¥åœ¨æ¨¡å‹ä¹‹å¤–ï¼Œæä¾›é¢å¤–çš„å®‰å…¨ä¿æŠ¤ã€‚è¿™æ˜¯é€šè¿‡å·¥ç¨‹ä¸Šçš„å¼ºåˆ¶æ£€æŸ¥å®ç°çš„ã€‚\n",
    "\n",
    "åœ¨ LangGraph ä¸­ï¼ŒæŠ¤æ å¯ä»¥é€šè¿‡ä¸­é—´ä»¶è½»æ¾å®ç°ã€‚ä¸‹é¢æˆ‘ä»¬å®ç°ä¸€ä¸ªç®€å•çš„æŠ¤æ ï¼šè‹¥ç”¨æˆ·çš„æœ€æ–°æ¶ˆæ¯ä¸­åŒ…å«æŸäº›æ•æ„Ÿè¯ï¼Œæ™ºèƒ½ä½“å°†æ‹’ç»å›ç­”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c5cc5b-7b4a-4658-8f86-feb8114d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain.agents.middleware import before_agent, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "banned_keywords = [\"hack\", \"exploit\", \"malware\"]\n",
    "\n",
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_filter(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "\n",
    "    # Check for banned keywords\n",
    "    for keyword in banned_keywords:\n",
    "        if keyword in content:\n",
    "            # Block execution before any processing\n",
    "            return {\n",
    "                \"messages\": [{\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "                }],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,\n",
    "    middleware=[content_filter],\n",
    ")\n",
    "\n",
    "# This request will be blocked before any processing\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55cad2e8-ab78-44d6-8682-1e0fe17469a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How do I hack into a database?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I cannot process requests containing inappropriate content. Please rephrase your request.\n"
     ]
    }
   ],
   "source": [
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761479b-d432-4e09-9341-4b5ad8363b48",
   "metadata": {},
   "source": [
    "## å››ã€PII æ£€æµ‹\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç»§ç»­ç¼–å†™æŠ¤æ ã€‚[PII](https://docs.langchain.com/oss/python/langchain/guardrails#pii-detection)ï¼ˆPersonally Identifiable Informationï¼‰æ£€æµ‹å¯ä»¥å‘ç°ç”¨æˆ·è¾“å…¥ä¸­çš„é‚®ç®±ã€IPã€åœ°å€ã€é“¶è¡Œå¡ç­‰éšç§ä¿¡æ¯ï¼Œå¹¶åšå‡ºå¤„ç½®ã€‚\n",
    "\n",
    "ä¸‹é¢çš„ä¾‹å­æ¥æºäºç”Ÿæ´»ã€‚æˆ‘ä»¬ç»å¸¸æŠŠæŠ¥é”™å¤åˆ¶ç»™å¤§æ¨¡å‹ï¼Œè®©å®ƒå¸®å¿™ debugã€‚ä½†æŠ¥é”™ä¸­å¯èƒ½åŒ…å«ä¸ªäººéšç§ä¿¡æ¯ã€‚é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œé‡‡ç”¨ä»¥ä¸‹ä¸¤ç§æ–¹æ³•è¿›è¡Œå¤„ç½®ï¼š\n",
    "\n",
    "1. æ‹’ç»å›ç­”é—®é¢˜\n",
    "2. å±è”½éšç§ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0697a36-a7f6-46dc-acf0-44eed2c56daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# å¯ä¿¡ä»»çš„æ¨¡å‹ï¼Œä¸€èˆ¬æ˜¯æœ¬åœ°æ¨¡å‹ï¼Œä¸ºäº†æ–¹ä¾¿ï¼Œè¿™é‡Œä¾ç„¶ä½¿ç”¨qwen\n",
    "trusted_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    ")\n",
    "\n",
    "# ç”¨äºæ ¼å¼åŒ–æ™ºèƒ½ä½“è¾“å‡ºï¼Œè‹¥å‘ç°æ•æ„Ÿä¿¡æ¯è¿”å›Trueï¼Œæ²¡å‘ç°è¿”å›False\n",
    "class PiiCheck(BaseModel):\n",
    "    \"\"\"Structured output indicating whether text contains PII.\"\"\"\n",
    "    is_pii: bool = Field(description=\"Whether the text contains PII\")\n",
    "\n",
    "def message_with_pii(pii_middleware):\n",
    "    agent = create_agent(\n",
    "        model=basic_model,\n",
    "        middleware=[pii_middleware],\n",
    "    )\n",
    "\n",
    "    # This request will be blocked before any processing\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": dedent(\n",
    "                \"\"\"\n",
    "                File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
    "                    agent = create_react_agent(\n",
    "                ---\n",
    "                æŠ¥é”™ä½ç½®åœ¨å“ª\n",
    "                \"\"\").strip()\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b344fe-5bb5-4349-9183-ed163b5fde4a",
   "metadata": {},
   "source": [
    "ğŸ‰ **å¤„ç½®æ–¹å¼ä¸€**ï¼šå¦‚é‡éšç§ä¿¡æ¯ï¼Œæ‹’ç»å›å¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6400b371-034f-4c71-8dd6-6c5f115a0b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_blocker(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "    prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·è¯†åˆ«ä¸‹é¢æ–‡æœ¬ä¸­æ¶‰åŠä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ï¼Œ\"\n",
    "        \"ä¾‹å¦‚ï¼šå§“åã€èº«ä»½è¯å·ã€æŠ¤ç…§å·ã€ç”µè¯å·ç ã€é‚®ç®±ã€ä½å€ã€é“¶è¡Œå¡å·ã€ç¤¾äº¤è´¦å·ã€è½¦ç‰Œç­‰ã€‚\"\n",
    "        \"ç‰¹åˆ«æ³¨æ„ï¼Œè‹¥ä»£ç ã€æ–‡ä»¶è·¯å¾„ä¸­åŒ…å«ç”¨æˆ·åï¼Œä¹Ÿåº”è¢«è§†ä¸ºæ•æ„Ÿä¿¡æ¯ã€‚\"\n",
    "        \"è‹¥åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œè¯·è¿”å›{\\\"is_pii\\\": True}ï¼Œå¦åˆ™è¿”å›{\\\"is_pii\\\": False}ã€‚\"\n",
    "        \"è¯·ä¸¥æ ¼ä»¥ json æ ¼å¼è¿”å›ï¼Œå¹¶ä¸”åªè¾“å‡º jsonã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + content\n",
    "    )\n",
    "\n",
    "    pii_agent = trusted_model.with_structured_output(PiiCheck)\n",
    "    result = pii_agent.invoke(prompt)\n",
    "\n",
    "    if result.is_pii is True:\n",
    "        # Block execution before any processing\n",
    "        return {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "            }],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "    else:\n",
    "        print(\"No PII found\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ba27fa-cb71-4dd2-b051-7ef949d1cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "---\n",
      "æŠ¥é”™ä½ç½®åœ¨å“ª\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I cannot process requests containing inappropriate content. Please rephrase your request.\n"
     ]
    }
   ],
   "source": [
    "result = message_with_pii(pii_middleware=content_blocker)\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9ad2b-18f9-41e1-995b-81572753f4d2",
   "metadata": {},
   "source": [
    "ğŸ€ **å¤„ç½®æ–¹å¼äºŒ**ï¼šå¦‚é‡æ•æ„Ÿä¿¡æ¯ï¼Œä½¿ç”¨ä¸€ä¸²  `*****` å·å±è”½éšç§ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7a946d8-fde3-4348-82e4-3801481a332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_filter(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "    prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·è¯†åˆ«ä¸‹é¢æ–‡æœ¬ä¸­æ¶‰åŠä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ï¼Œ\"\n",
    "        \"ä¾‹å¦‚ï¼šå§“åã€èº«ä»½è¯å·ã€æŠ¤ç…§å·ã€ç”µè¯å·ç ã€é‚®ç®±ã€ä½å€ã€é“¶è¡Œå¡å·ã€ç¤¾äº¤è´¦å·ã€è½¦ç‰Œç­‰ã€‚\"\n",
    "        \"ç‰¹åˆ«æ³¨æ„ï¼Œè‹¥ä»£ç ã€æ–‡ä»¶è·¯å¾„ä¸­åŒ…å«ç”¨æˆ·åï¼Œä¹Ÿåº”è¢«è§†ä¸ºæ•æ„Ÿä¿¡æ¯ã€‚\"\n",
    "        \"è‹¥åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œè¯·è¿”å›{\\\"is_pii\\\": True}ï¼Œå¦åˆ™è¿”å›{\\\"is_pii\\\": False}ã€‚\"\n",
    "        \"è¯·ä¸¥æ ¼ä»¥ json æ ¼å¼è¿”å›ï¼Œå¹¶ä¸”åªè¾“å‡º jsonã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + content\n",
    "    )\n",
    "\n",
    "    pii_agent = trusted_model.with_structured_output(PiiCheck)\n",
    "    result = pii_agent.invoke(prompt)\n",
    "\n",
    "    if result.is_pii is True:\n",
    "        mask_prompt = (\n",
    "            \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·å°†ä¸‹é¢æ–‡æœ¬ä¸­çš„æ‰€æœ‰ä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ç”¨æ˜Ÿå·ï¼ˆ*ï¼‰æ›¿æ¢ã€‚\"\n",
    "            \"ä»…æ›¿æ¢æ•æ„Ÿç‰‡æ®µï¼Œå…¶ä»–æ–‡æœ¬ä¿æŒä¸å˜ã€‚\"\n",
    "            \"åªè¾“å‡ºå¤„ç†åçš„æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–é¢å¤–å†…å®¹ã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + last_message.content\n",
    "        )\n",
    "        masked_message = basic_model.invoke(mask_prompt)\n",
    "        return {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": masked_message.content\n",
    "            }]\n",
    "        }\n",
    "    else:\n",
    "        print(\"No PII found\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2480e24d-39b9-4329-a008-6b162850f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "---\n",
      "æŠ¥é”™ä½ç½®åœ¨å“ª\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "File \"/home/********/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "---\n",
      "æŠ¥é”™ä½ç½®åœ¨å“ª\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ ¹æ®ä½ æä¾›çš„é”™è¯¯ä¿¡æ¯ï¼ŒæŠ¥é”™ä½ç½®åœ¨ï¼š\n",
      "\n",
      "**æ–‡ä»¶è·¯å¾„**: `/home/luochang/proj/agent.py`  \n",
      "**è¡Œå·**: ç¬¬ 53 è¡Œ  \n",
      "**å‡½æ•°**: `my_agent` å‡½æ•°ä¸­  \n",
      "**å…·ä½“ä»£ç **: `agent = create_react_agent(` è¿™ä¸€è¡Œ\n",
      "\n",
      "---\n",
      "\n",
      "### å¯èƒ½çš„é”™è¯¯åŸå› \n",
      "`create_react_agent` æ˜¯ LangChain åº“ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆ›å»º ReActï¼ˆReasoning + Actionï¼‰é£æ ¼çš„ Agentã€‚æŠ¥é”™å¯èƒ½ç”±ä»¥ä¸‹å‡ ç§æƒ…å†µå¼•èµ·ï¼š\n",
      "\n",
      "1. **ç¼ºå°‘å¿…è¦çš„å‚æ•°**ï¼š\n",
      "   - `create_react_agent` éœ€è¦ä¼ å…¥ `llm`ï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰ã€`tools`ï¼ˆå·¥å…·åˆ—è¡¨ï¼‰ç­‰å‚æ•°ã€‚\n",
      "   - ç¤ºä¾‹ï¼š\n",
      "     ```python\n",
      "     from langchain.agents import create_react_agent\n",
      "     from langchain.llms import OpenAI\n",
      "     from langchain.tools import Tool\n",
      "\n",
      "     llm = OpenAI()\n",
      "     tools = [Tool(...)]\n",
      "     agent = create_react_agent(llm=llm, tools=tools)\n",
      "     ```\n",
      "\n",
      "2. **å‚æ•°ç±»å‹ä¸åŒ¹é…**ï¼š\n",
      "   - ç¡®ä¿ä¼ å…¥çš„ `llm` å’Œ `tools` ç±»å‹æ­£ç¡®ã€‚\n",
      "\n",
      "3. **æœªå¯¼å…¥ä¾èµ–æ¨¡å—**ï¼š\n",
      "   - æ£€æŸ¥æ˜¯å¦å·²æ­£ç¡®å®‰è£…å¹¶å¯¼å…¥ `langchain` ç›¸å…³æ¨¡å—ã€‚\n",
      "\n",
      "4. **LangChain ç‰ˆæœ¬é—®é¢˜**ï¼š\n",
      "   - å¦‚æœä½¿ç”¨çš„æ˜¯æ—§ç‰ˆæœ¬æˆ–æ–°ç‰ˆæœ¬ï¼ŒAPI å¯èƒ½æœ‰å˜åŒ–ï¼Œè¯·ç¡®è®¤å½“å‰ç‰ˆæœ¬æ”¯æŒè¯¥æ–¹æ³•ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### è§£å†³å»ºè®®\n",
      "è¯·æä¾›å®Œæ•´çš„æŠ¥é”™ä¿¡æ¯ï¼ˆä¾‹å¦‚ TypeErrorã€ImportError ç­‰ï¼‰ï¼Œè¿™æ ·å¯ä»¥æ›´å‡†ç¡®åœ°å®šä½é—®é¢˜ã€‚åŒæ—¶æ£€æŸ¥ä»¥ä¸‹å†…å®¹ï¼š\n",
      "\n",
      "- æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–äº† LLM å’Œ Toolsï¼Ÿ\n",
      "- æ˜¯å¦é—æ¼äº†æŸäº›å¿…éœ€å‚æ•°ï¼Ÿ\n",
      "\n",
      "å¦‚æœä½ èƒ½è´´å‡ºç¬¬ 53 è¡Œé™„è¿‘çš„å®Œæ•´ä»£ç æ®µå’ŒæŠ¥é”™å †æ ˆï¼Œæˆ‘å¯ä»¥å¸®ä½ è¿›ä¸€æ­¥åˆ†æå…·ä½“é—®é¢˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "result = message_with_pii(pii_middleware=content_filter)\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d7771-f9b8-4408-9387-c67c51c1a155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
