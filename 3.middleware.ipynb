{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da96a78-5bcd-4ea3-b5cc-addb660a1554",
   "metadata": {},
   "source": [
    "# ä¸­é—´ä»¶\n",
    "\n",
    "[ä¸­é—´ä»¶](https://docs.langchain.com/oss/python/langchain/middleware/overview)ï¼ˆmiddlewareï¼‰æ˜¯æœ¬æ¬¡æ›´æ–°ä¸­æœ€äº®çœ¼çš„ç‰¹æ€§ï¼Œè¯¸å¤šæ–°åŠŸèƒ½å‡è—‰ç”±ä¸­é—´ä»¶å®ç°ï¼Œæ¯”å¦‚äººæœºäº¤äº’ã€åŠ¨æ€ç³»ç»Ÿæç¤ºè¯ã€åŠ¨æ€æ³¨å…¥ä¸Šä¸‹æ–‡ç­‰ç­‰ã€‚å¯ä»¥å°†ä¸­é—´ä»¶è§†ä¸ºä¸€ç§é’©å­å‡½æ•°ã€‚é€šè¿‡å‘å·¥ä½œæµé¢„åŸ‹ä¸­é—´ä»¶ï¼Œèƒ½å¤Ÿå®ç°å·¥ä½œæµçš„é«˜æ•ˆæ‹“å±•å’Œå¯å®šåˆ¶åŒ–ã€‚\n",
    "\n",
    "LangChain å¯é€šè¿‡ [è£…é¥°å™¨](https://reference.langchain.com/python/langchain/middleware/#decorators) åˆ›å»º **è‡ªå®šä¹‰ä¸­é—´ä»¶**ã€‚\n",
    "\n",
    "<details>\n",
    "  <summary>è£…é¥°å™¨åˆ—è¡¨ï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>\n",
    "\n",
    "  | DECORATOR | DESCRIPTION |\n",
    "  | -- | -- |\n",
    "  | `@before_agent` | åœ¨ Agent æ‰§è¡Œå‰æ‰§è¡Œé€»è¾‘ |\n",
    "  | `@after_agent` | åœ¨ Agent æ‰§è¡Œåæ‰§è¡Œé€»è¾‘ |\n",
    "  | `@before_model` | åœ¨æ¯æ¬¡æ¨¡å‹è°ƒç”¨å‰æ‰§è¡Œé€»è¾‘ |\n",
    "  | `@after_model` | åœ¨æ¯æ¬¡æ¨¡å‹æ”¶åˆ°å“åº”åæ‰§è¡Œé€»è¾‘ |\n",
    "  | `@wrap_model_call` | æ§åˆ¶æ¨¡å‹çš„è°ƒç”¨è¿‡ç¨‹ |\n",
    "  | `@wrap_tool_call` | æ§åˆ¶å·¥å…·çš„è°ƒç”¨è¿‡ç¨‹ |\n",
    "  | `@dynamic_prompt` | åŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ |\n",
    "  | `@hook_config` | é…ç½®é’©å­è¡Œä¸º |\n",
    "\n",
    "</details>\n",
    "\n",
    "**è£…é¥°å™¨ç±»å‹** å†³å®šä¸­é—´ä»¶åœ¨å·¥ä½œæµä¸­çš„æ‰§è¡Œä½ç½®ã€‚æ¯”å¦‚ä½¿ç”¨ `@before_model` è£…é¥°å™¨ï¼Œèƒ½å¤Ÿåœ¨æ¨¡å‹è°ƒç”¨å‰æ‰§è¡Œè‡ªå®šä¹‰é€»è¾‘ã€‚**è¢«è£…é¥°å‡½æ•°** è´Ÿè´£è¿™æ®µè‡ªå®šä¹‰é€»è¾‘çš„å…·ä½“å®ç°ã€‚è¿™ä¹ˆè¯´å¯èƒ½æœ‰ç‚¹æŠ½è±¡ã€‚æ²¡å…³ç³»ï¼Œæœ¬èŠ‚æä¾›äº†å››ä¸ªä¾‹å­ï¼Œçœ‹å®Œä½ ä¸€å®šèƒ½å¤Ÿæ„Ÿæ‚Ÿåˆ°ä¸­é—´ä»¶çš„ä½¿ç”¨æ–¹æ³•ï¼š\n",
    "\n",
    "- é¢„ç®—æ§åˆ¶\n",
    "- æ¶ˆæ¯æˆªæ–­\n",
    "- æ•æ„Ÿè¯è¿‡æ»¤\n",
    "- PII æ£€æµ‹`ï¼ˆä¸ªäººéšç§ä¿¡æ¯æ£€æµ‹ï¼‰`\n",
    "\n",
    "## ä¸€ã€é¢„ç®—æ§åˆ¶\n",
    "\n",
    "éšç€å¯¹è¯è½®æ¬¡å¢åŠ ï¼Œæ¯æ¬¡è¯·æ±‚æºå¸¦çš„å¯¹è¯è®°å½•ä¹Ÿä¼šè¶Šæ¥è¶Šé•¿ï¼Œä»è€Œå¯¼è‡´è¯·æ±‚è´¹ç”¨ä¸Šå‡ã€‚ä¸ºäº†æ§åˆ¶é¢„ç®—ï¼Œå¯ä»¥è®¾å®šåœ¨å¯¹è¯è½®æ¬¡è¶…è¿‡æŸä¸ªé˜ˆå€¼åï¼Œåˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ã€‚è¿™ä¸ªåŠŸèƒ½å¯ä»¥é€šè¿‡è‡ªå®šä¹‰ä¸­é—´ä»¶å®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd14ba5-4b0c-4cfb-a976-040d0a365f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# åŠ è½½æ¨¡å‹é…ç½®\n",
    "_ = load_dotenv()\n",
    "\n",
    "# ä½è´¹ç‡æ¨¡å‹\n",
    "basic_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    ")\n",
    "\n",
    "# é«˜è´¹ç‡æ¨¡å‹\n",
    "advanced_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4033cbf-b59f-4a6b-9fd1-f102b7fea252",
   "metadata": {},
   "source": [
    "ç”±äºæˆ‘ä»¬çš„ä¿®æ”¹æ¶‰åŠåˆ°æ¨¡å‹æ¨ç†æœ¬èº«ï¼Œ`@before_model` å’Œ `@after_model` åœ¨è¿™é‡Œå·²ç»ä¸å¤Ÿç”¨äº†ã€‚æˆ‘ä»¬ä½¿ç”¨èƒ½å¹²æ¶‰æ¨¡å‹è°ƒç”¨çš„ [`@wrap_model_call`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_model_call) è£…é¥°å™¨ã€‚å…·ä½“é€»è¾‘ç”±è¢«è£…é¥°å‡½æ•° `dynamic_model_selection` å®ç°ï¼šå½“å†å²å¯¹è¯è¶…è¿‡ 5 æ¡æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e758792-47d8-4ea4-857e-dddbbc71eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 5:\n",
    "        # Use a basic model for longer conversations\n",
    "        model = basic_model\n",
    "    else:\n",
    "        model = advanced_model\n",
    "\n",
    "    request.model = model\n",
    "    print(f\"message_count: {message_count}\")\n",
    "    print(f\"model_name: {model.model_name}\")\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=advanced_model,  # Default model\n",
    "    middleware=[dynamic_model_selection]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850013a4",
   "metadata": {},
   "source": [
    "ä»ä¸‹é¢çš„ä¾‹å­å¯ä»¥çœ‹åˆ°ï¼Œå½“å†å²å¯¹è¯æ•° `message_count` è¶…è¿‡ 5 æ¡æ—¶ï¼Œç¡®å®ä»é«˜è´¹ç‡æ¨¡å‹ `qwen3-max` åˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ `qwen3-coder-plus`ã€‚æˆ‘ä»¬æ­£ç¡®åœ°å®ç°äº†é¢„ç®—æ§åˆ¶åŠŸèƒ½ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b4ed25-2ef8-4a24-9760-89f1ed34bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 ===\n",
      "message_count: 1\n",
      "model_name: qwen3-max\n",
      "content: æ™®é€šæ±½è½¦é€šå¸¸æœ‰4ä¸ªè½®å­ã€‚\n",
      "\n",
      "=== Round 2 ===\n",
      "message_count: 3\n",
      "model_name: qwen3-max\n",
      "content: é£æœºè½®å­æ•°é‡ä¸å›ºå®šï¼Œå¸¸è§çš„å®¢æœºä¸€èˆ¬æœ‰3ä¸ªèµ·è½æ¶ï¼ˆå‰1ä¸ªã€ä¸»èµ·è½æ¶2ä¸ªï¼‰ï¼Œæ€»å…±6åˆ°10ä¸ªè½®å­ã€‚\n",
      "\n",
      "=== Round 3 ===\n",
      "message_count: 5\n",
      "model_name: qwen3-max\n",
      "content: æ‘©æ‰˜è½¦é€šå¸¸æœ‰2ä¸ªè½®å­ã€‚\n",
      "\n",
      "=== Round 4 ===\n",
      "message_count: 7\n",
      "model_name: qwen3-coder-plus\n",
      "content: è‡ªè¡Œè½¦æœ‰2ä¸ªè½®å­ã€‚\n"
     ]
    }
   ],
   "source": [
    "state: MessagesState = {\"messages\": []}\n",
    "items = ['æ±½è½¦', 'é£æœº', 'æ‘©æ‰˜è½¦', 'è‡ªè¡Œè½¦']\n",
    "for idx, i in enumerate(items):\n",
    "    print(f\"\\n=== Round {idx+1} ===\")\n",
    "    state[\"messages\"] += [HumanMessage(content=f\"{i}æœ‰å‡ ä¸ªè½®å­ï¼Œè¯·ç®€å•å›ç­”\")]\n",
    "    result = agent.invoke(state)\n",
    "    state[\"messages\"] = result[\"messages\"]\n",
    "    print(f'content: {result[\"messages\"][-1].content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc58247-324d-40fe-83e5-b34f9ec564e6",
   "metadata": {},
   "source": [
    "## äºŒã€æ¶ˆæ¯æˆªæ–­\n",
    "\n",
    "æ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡å­˜åœ¨é•¿åº¦é™åˆ¶ã€‚ä¸€æ—¦è¶…è¿‡é™åˆ¶ï¼Œå°±éœ€è¦å¯¹ä¸Šä¸‹æ–‡è¿›è¡Œå‹ç¼©ã€‚åœ¨ä¼—å¤šæ–¹æ³•ä¸­ï¼Œæˆªæ–­æ˜¯æœ€ç®€å•ç²—æš´ã€æ˜“äºå®ç°çš„æ–¹æ³•ã€‚æ¶ˆæ¯æˆªæ–­åŠŸèƒ½å¯ä»¥é€šè¿‡ `@before_model` è£…é¥°å™¨å®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08619c1-6940-4043-be1b-3282be16c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750eee1-a873-424c-878b-61ec5bf81f0e",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°è¯•ä¸€ç§æˆªæ–­ç­–ç•¥ï¼šåœ¨ä¿ç•™æœ€è¿‘æ¶ˆæ¯çš„åŒæ—¶ï¼Œé¢å¤–ä¿ç•™ç¬¬ä¸€æ¡æ¶ˆæ¯ã€‚åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œç”±äºæˆ‘ä»¬åœ¨ç¬¬ä¸€æ¡æ¶ˆæ¯ä¸­å‘Šè¯‰æ™ºèƒ½ä½“ã€Œæˆ‘æ˜¯ bobã€ï¼Œå› æ­¤å®ƒè®°å¾—æˆ‘æ˜¯ bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefc09f4-d67f-4a7a-b930-171043e0a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! You introduced yourself earlier.\n"
     ]
    }
   ],
   "source": [
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    basic_model,\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "def agent_invoke(agent):\n",
    "    agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "    agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "    agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "    final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "    \n",
    "    final_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "agent_invoke(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2afa04-18ad-487d-9cef-dfba0b5ec36d",
   "metadata": {},
   "source": [
    "å½“ç„¶ï¼Œè¿™ä¸ªè¡¨ç°ä¸è¶³ä»¥è¯´æ˜æˆªæ–­ä¸­é—´ä»¶çœŸçš„ç”Ÿæ•ˆäº†ã€‚è‹¥è¿™ä¸ªä¸­é—´ä»¶ä»æœªç”Ÿæ•ˆï¼Œä¹Ÿä¼šæœ‰è¿™æ ·çš„ç»“æœã€‚ä¸ºäº†è¯æ˜å®ƒçœŸçš„ç”Ÿæ•ˆäº†ï¼Œæˆ‘ä»¬å†æ¬¡ä¿®æ”¹æˆªæ–­ç­–ç•¥ã€‚è¿™æ¬¡åªä¿ç•™æœ€åä¸¤æ¡å¯¹è¯è®°å½•ã€‚å¦‚æœæ™ºèƒ½ä½“ä¸è®°å¾—æˆ‘æ˜¯ bobï¼Œè¯´æ˜æˆªæ–­ä¸­é—´ä»¶ç¡®å®èµ·ä½œç”¨äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc2a8e62-b7c4-4275-8967-7c551a73c6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't actually know your name! You haven't shared that information with me yet. I'd be happy to learn what you'd like to be called - would you like to tell me your name?\n"
     ]
    }
   ],
   "source": [
    "@before_model\n",
    "def trim_without_first_message(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *messages[-2:]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    basic_model,\n",
    "    middleware=[trim_without_first_message],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "agent_invoke(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e989c",
   "metadata": {},
   "source": [
    "ç°åœ¨æ™ºèƒ½ä½“ä¸è®°å¾—æˆ‘æ˜¯è°ï¼Œè¯´æ˜ä¸­é—´ä»¶ç¡®å®ç”Ÿæ•ˆäº†ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1220c4b-13f2-48e0-90d8-3fb2bc92e5bd",
   "metadata": {},
   "source": [
    "## ä¸‰ã€æ•æ„Ÿè¯è¿‡æ»¤\n",
    "\n",
    "**æŠ¤æ **ï¼ˆGuardrailsï¼‰æ˜¯æ™ºèƒ½ä½“æä¾›çš„ä¸€ç±»å†…å®¹å®‰å…¨èƒ½åŠ›çš„ç»Ÿç§°ã€‚å¤§æ¨¡å‹æœ¬èº«å…·å¤‡ä¸€å®šçš„å†…å®¹é£æ§èƒ½åŠ›ï¼Œä½†å¾ˆå®¹æ˜“è¢«çªç ´ã€‚æœç´¢ã€Œå¤§æ¨¡å‹ç ´ç”²ã€å°±èƒ½æ‰¾åˆ°æ­¤ç±»æ•™ç¨‹ã€‚æ™ºèƒ½ä½“å¯ä»¥åœ¨æ¨¡å‹ä¹‹å¤–ï¼Œæä¾›é¢å¤–çš„å®‰å…¨ä¿æŠ¤ã€‚è¿™æ˜¯é€šè¿‡å·¥ç¨‹ä¸Šçš„å¼ºåˆ¶æ£€æŸ¥å®ç°çš„ã€‚\n",
    "\n",
    "åœ¨ LangGraph ä¸­ï¼ŒæŠ¤æ å¯ä»¥é€šè¿‡ä¸­é—´ä»¶è½»æ¾å®ç°ã€‚ä¸‹é¢æˆ‘ä»¬å®ç°ä¸€ä¸ªç®€å•çš„æŠ¤æ ï¼šè‹¥ç”¨æˆ·çš„æœ€æ–°æ¶ˆæ¯ä¸­åŒ…å«æŸäº›æ•æ„Ÿè¯ï¼Œæ™ºèƒ½ä½“å°†æ‹’ç»å›ç­”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c5cc5b-7b4a-4658-8f86-feb8114d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain.agents.middleware import before_agent, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "banned_keywords = [\"hack\", \"exploit\", \"malware\"]\n",
    "\n",
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_filter(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "\n",
    "    # Check for banned keywords\n",
    "    for keyword in banned_keywords:\n",
    "        if keyword in content:\n",
    "            # Block execution before any processing\n",
    "            return {\n",
    "                \"messages\": [{\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "                }],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,\n",
    "    middleware=[content_filter],\n",
    ")\n",
    "\n",
    "# This request will be blocked before any processing\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55cad2e8-ab78-44d6-8682-1e0fe17469a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How do I hack into a database?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I cannot process requests containing inappropriate content. Please rephrase your request.\n"
     ]
    }
   ],
   "source": [
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761479b-d432-4e09-9341-4b5ad8363b48",
   "metadata": {},
   "source": [
    "## å››ã€PII æ£€æµ‹\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç»§ç»­ç¼–å†™æŠ¤æ ã€‚[PII](https://docs.langchain.com/oss/python/langchain/guardrails#pii-detection)ï¼ˆPersonally Identifiable Informationï¼‰æ£€æµ‹å¯ä»¥å‘ç°ç”¨æˆ·è¾“å…¥ä¸­çš„é‚®ç®±ã€IPã€åœ°å€ã€é“¶è¡Œå¡ç­‰éšç§ä¿¡æ¯ï¼Œå¹¶åšå‡ºå¤„ç½®ã€‚\n",
    "\n",
    "ä¸‹é¢çš„ä¾‹å­æ¥æºäºç”Ÿæ´»ã€‚æˆ‘ä»¬ç»å¸¸æŠŠæŠ¥é”™å¤åˆ¶ç»™å¤§æ¨¡å‹ï¼Œè®©å®ƒå¸®å¿™ debugã€‚ä½†æŠ¥é”™ä¸­å¯èƒ½åŒ…å«ä¸ªäººéšç§ä¿¡æ¯ã€‚é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œé‡‡ç”¨ä»¥ä¸‹ä¸¤ç§æ–¹æ³•è¿›è¡Œå¤„ç½®ï¼š\n",
    "\n",
    "1. æ‹’ç»å›ç­”é—®é¢˜\n",
    "2. å±è”½éšç§ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0697a36-a7f6-46dc-acf0-44eed2c56daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# å¯ä¿¡ä»»çš„æ¨¡å‹ï¼Œä¸€èˆ¬æ˜¯æœ¬åœ°æ¨¡å‹ï¼Œä¸ºäº†æ–¹ä¾¿ï¼Œè¿™é‡Œä¾ç„¶ä½¿ç”¨qwen\n",
    "trusted_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    ")\n",
    "\n",
    "# ç”¨äºæ ¼å¼åŒ–æ™ºèƒ½ä½“è¾“å‡ºï¼Œè‹¥å‘ç°æ•æ„Ÿä¿¡æ¯è¿”å›Trueï¼Œæ²¡å‘ç°è¿”å›False\n",
    "class PiiCheck(BaseModel):\n",
    "    \"\"\"Structured output indicating whether text contains PII.\"\"\"\n",
    "    is_pii: bool = Field(description=\"Whether the text contains PII\")\n",
    "\n",
    "def message_with_pii(pii_middleware):\n",
    "    agent = create_agent(\n",
    "        model=basic_model,\n",
    "        middleware=[pii_middleware],\n",
    "    )\n",
    "\n",
    "    # This request will be blocked before any processing\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": dedent(\n",
    "                \"\"\"\n",
    "                File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
    "                    agent = create_react_agent(\n",
    "                            ^^^^^^^^^^^^^^^^^^^\n",
    "                File \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n",
    "                    return arg(*args, **kwargs)\n",
    "                        ^^^^^^^^^^^^^^^^^^^^\n",
    "                File \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n",
    "                    model = cast(BaseChatModel, model).bind_tools(\n",
    "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "                AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n",
    "    \n",
    "                ---\n",
    "    \n",
    "                ä¸ºå•¥æŠ¥é”™\n",
    "                \"\"\").strip()\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b344fe-5bb5-4349-9183-ed163b5fde4a",
   "metadata": {},
   "source": [
    "ğŸ‰ **å¤„ç½®æ–¹å¼ä¸€**ï¼šå¦‚é‡éšç§ä¿¡æ¯ï¼Œæ‹’ç»å›å¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6400b371-034f-4c71-8dd6-6c5f115a0b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_blocker(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "    prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·è¯†åˆ«ä¸‹é¢æ–‡æœ¬ä¸­æ¶‰åŠä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ï¼Œ\"\n",
    "        \"ä¾‹å¦‚ï¼šå§“åã€èº«ä»½è¯å·ã€æŠ¤ç…§å·ã€ç”µè¯å·ç ã€é‚®ç®±ã€ä½å€ã€é“¶è¡Œå¡å·ã€ç¤¾äº¤è´¦å·ã€è½¦ç‰Œç­‰ã€‚\"\n",
    "        \"ç‰¹åˆ«æ³¨æ„ï¼Œè‹¥ä»£ç ã€æ–‡ä»¶è·¯å¾„ä¸­åŒ…å«ç”¨æˆ·åï¼Œä¹Ÿåº”è¢«è§†ä¸ºæ•æ„Ÿä¿¡æ¯ã€‚\"\n",
    "        \"è‹¥åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œè¯·è¿”å›{\\\"is_pii\\\": True}ï¼Œå¦åˆ™è¿”å›{\\\"is_pii\\\": False}ã€‚\"\n",
    "        \"è¯·ä¸¥æ ¼ä»¥ json æ ¼å¼è¿”å›ï¼Œå¹¶ä¸”åªè¾“å‡º jsonã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + content\n",
    "    )\n",
    "\n",
    "    pii_agent = trusted_model.with_structured_output(PiiCheck)\n",
    "    result = pii_agent.invoke(prompt)\n",
    "\n",
    "    if result.is_pii is True:\n",
    "        # Block execution before any processing\n",
    "        return {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "            }],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "    else:\n",
    "        print(\"No PII found\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ba27fa-cb71-4dd2-b051-7ef949d1cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n",
      "    return arg(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n",
      "    model = cast(BaseChatModel, model).bind_tools(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n",
      "\n",
      "---\n",
      "\n",
      "ä¸ºå•¥æŠ¥é”™\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I cannot process requests containing inappropriate content. Please rephrase your request.\n"
     ]
    }
   ],
   "source": [
    "result = message_with_pii(pii_middleware=content_blocker)\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9ad2b-18f9-41e1-995b-81572753f4d2",
   "metadata": {},
   "source": [
    "ğŸ€ **å¤„ç½®æ–¹å¼äºŒ**ï¼šå¦‚é‡æ•æ„Ÿä¿¡æ¯ï¼Œä½¿ç”¨ä¸€ä¸²  `*****` å·å±è”½éšç§ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7a946d8-fde3-4348-82e4-3801481a332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_filter(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "    prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·è¯†åˆ«ä¸‹é¢æ–‡æœ¬ä¸­æ¶‰åŠä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ï¼Œ\"\n",
    "        \"ä¾‹å¦‚ï¼šå§“åã€èº«ä»½è¯å·ã€æŠ¤ç…§å·ã€ç”µè¯å·ç ã€é‚®ç®±ã€ä½å€ã€é“¶è¡Œå¡å·ã€ç¤¾äº¤è´¦å·ã€è½¦ç‰Œç­‰ã€‚\"\n",
    "        \"ç‰¹åˆ«æ³¨æ„ï¼Œè‹¥ä»£ç ã€æ–‡ä»¶è·¯å¾„ä¸­åŒ…å«ç”¨æˆ·åï¼Œä¹Ÿåº”è¢«è§†ä¸ºæ•æ„Ÿä¿¡æ¯ã€‚\"\n",
    "        \"è‹¥åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œè¯·è¿”å›{\\\"is_pii\\\": True}ï¼Œå¦åˆ™è¿”å›{\\\"is_pii\\\": False}ã€‚\"\n",
    "        \"è¯·ä¸¥æ ¼ä»¥ json æ ¼å¼è¿”å›ï¼Œå¹¶ä¸”åªè¾“å‡º jsonã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + content\n",
    "    )\n",
    "\n",
    "    pii_agent = trusted_model.with_structured_output(PiiCheck)\n",
    "    result = pii_agent.invoke(prompt)\n",
    "\n",
    "    if result.is_pii is True:\n",
    "        mask_prompt = (\n",
    "            \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·å°†ä¸‹é¢æ–‡æœ¬ä¸­çš„æ‰€æœ‰ä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ç”¨æ˜Ÿå·ï¼ˆ*ï¼‰æ›¿æ¢ã€‚\"\n",
    "            \"ä»…æ›¿æ¢æ•æ„Ÿç‰‡æ®µï¼Œå…¶ä»–æ–‡æœ¬ä¿æŒä¸å˜ã€‚\"\n",
    "            \"åªè¾“å‡ºå¤„ç†åçš„æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–é¢å¤–å†…å®¹ã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + last_message.content\n",
    "        )\n",
    "        masked_message = basic_model.invoke(mask_prompt)\n",
    "        return {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": masked_message.content\n",
    "            }]\n",
    "        }\n",
    "    else:\n",
    "        print(\"No PII found\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2480e24d-39b9-4329-a008-6b162850f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n",
      "    return arg(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n",
      "    model = cast(BaseChatModel, model).bind_tools(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n",
      "\n",
      "---\n",
      "\n",
      "ä¸ºå•¥æŠ¥é”™\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "File \"/home/********/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/********/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n",
      "    return arg(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/********/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n",
      "    model = cast(BaseChatModel, model).bind_tools(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n",
      "\n",
      "---\n",
      "\n",
      "ä¸ºå•¥æŠ¥é”™\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "è¿™ä¸ªé”™è¯¯çš„åŸå› æ˜¯ï¼š**ä½ ä¼ ç»™ `create_react_agent` çš„ model å‚æ•°æ˜¯ä¸€ä¸ª `RunnableLambda` å¯¹è±¡ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªèŠå¤©æ¨¡å‹å¯¹è±¡**ã€‚\n",
      "\n",
      "## é”™è¯¯åˆ†æ\n",
      "\n",
      "`create_react_agent` å‡½æ•°æœŸæœ›æ¥æ”¶ä¸€ä¸ªå®ç°äº† `bind_tools` æ–¹æ³•çš„èŠå¤©æ¨¡å‹ï¼ˆå¦‚ `ChatOpenAI`ã€`ChatAnthropic` ç­‰ï¼‰ï¼Œä½†ä½ ä¼ å…¥çš„æ˜¯ä¸€ä¸ª `RunnableLambda` å¯¹è±¡ï¼Œå®ƒæ²¡æœ‰ `bind_tools` æ–¹æ³•ã€‚\n",
      "\n",
      "## å¸¸è§åŸå› å’Œè§£å†³æ–¹æ¡ˆ\n",
      "\n",
      "### 1. ç›´æ¥ä¼ å…¥äº† RunnableLambda è€Œä¸æ˜¯æ¨¡å‹\n",
      "\n",
      "**é”™è¯¯å†™æ³•ï¼š**\n",
      "```python\n",
      "from langchain_core.runnables import RunnableLambda\n",
      "\n",
      "# é”™è¯¯ï¼šç›´æ¥ç”¨ RunnableLambda ä½œä¸ºæ¨¡å‹\n",
      "model = RunnableLambda(some_function)\n",
      "agent = create_react_agent(model, tools)  # è¿™é‡Œä¼šæŠ¥é”™\n",
      "```\n",
      "\n",
      "**æ­£ç¡®å†™æ³•ï¼š**\n",
      "```python\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "# æ­£ç¡®ï¼šä½¿ç”¨çœŸæ­£çš„èŠå¤©æ¨¡å‹\n",
      "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
      "agent = create_react_agent(model, tools)\n",
      "```\n",
      "\n",
      "### 2. æ¨¡å‹è¢«åŒ…è£…æˆäº† RunnableLambda\n",
      "\n",
      "**å¯èƒ½çš„é”™è¯¯æƒ…å†µï¼š**\n",
      "```python\n",
      "# å¦‚æœä½ åœ¨æŸä¸ªåœ°æ–¹è¿™æ ·åšäº†\n",
      "model = RunnableLambda(lambda x: some_chat_model.invoke(x))\n",
      "```\n",
      "\n",
      "**è§£å†³æ–¹æ³•ï¼šç›´æ¥ä½¿ç”¨åŸå§‹æ¨¡å‹**\n",
      "\n",
      "### 3. æ£€æŸ¥ä½ çš„ä»£ç \n",
      "\n",
      "åœ¨è°ƒç”¨ `create_react_agent` ä¹‹å‰ï¼Œæ£€æŸ¥ä½ çš„ model å˜é‡ï¼š\n",
      "\n",
      "```python\n",
      "print(type(model))  # åº”è¯¥æ˜¾ç¤ºç±»ä¼¼ <class 'langchain_openai.chat_models.ChatOpenAI'>\n",
      "\n",
      "# ç¡®ä¿ä½ çš„å¯¼å…¥æ­£ç¡®\n",
      "from langchain_openai import ChatOpenAI\n",
      "# æˆ–è€…\n",
      "from langchain_anthropic import ChatAnthropic\n",
      "# æˆ–è€…å…¶ä»–æ”¯æŒçš„èŠå¤©æ¨¡å‹\n",
      "\n",
      "model = ChatOpenAI(model=\"gpt-3.5-turbo\")  # æˆ–å…¶ä»–æ¨¡å‹\n",
      "agent = create_react_agent(model, tools)\n",
      "```\n",
      "\n",
      "## å®Œæ•´çš„æ­£ç¡®ç¤ºä¾‹\n",
      "\n",
      "```python\n",
      "from langchain_openai import ChatOpenAI\n",
      "from langgraph.prebuilt import create_react_agent\n",
      "\n",
      "# ä½¿ç”¨æ­£ç¡®çš„èŠå¤©æ¨¡å‹\n",
      "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
      "\n",
      "# åˆ›å»ºå·¥å…·åˆ—è¡¨\n",
      "tools = [tool1, tool2]  # ä½ çš„å·¥å…·\n",
      "\n",
      "# åˆ›å»º agent\n",
      "agent = create_react_agent(model, tools)\n",
      "```\n",
      "\n",
      "æ£€æŸ¥ä¸€ä¸‹ä½ çš„ç¬¬53è¡Œé™„è¿‘çš„ä»£ç ï¼Œç¡®ä¿ä¼ ç»™ `create_react_agent` çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ä¸€ä¸ªçœŸæ­£çš„èŠå¤©æ¨¡å‹å¯¹è±¡ã€‚\n"
     ]
    }
   ],
   "source": [
    "result = message_with_pii(pii_middleware=content_filter)\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d7771-f9b8-4408-9387-c67c51c1a155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
