{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da96a78-5bcd-4ea3-b5cc-addb660a1554",
   "metadata": {},
   "source": [
    "# ä¸­é—´ä»¶\n",
    "\n",
    "[ä¸­é—´ä»¶](https://docs.langchain.com/oss/python/langchain/middleware/overview)ï¼ˆmiddlewareï¼‰æ˜¯æœ¬æ¬¡æ›´æ–°ä¸­æœ€äº®çœ¼çš„ç‰¹æ€§ï¼Œè¯¸å¤šæ–°åŠŸèƒ½éƒ½æ˜¯è—‰ç”±ä¸­é—´ä»¶å®ç°çš„ï¼Œæ¯”å¦‚åŠ¨æ€ç³»ç»Ÿæç¤ºè¯ã€äººæœºäº¤äº’ã€åŠ¨æ€æ³¨å…¥ä¸Šä¸‹æ–‡ç­‰ç­‰ã€‚\n",
    "\n",
    "æœ¬èŠ‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸­é—´ä»¶å®ç°å››ä¸ªåŠŸèƒ½ï¼š\n",
    "\n",
    "- é¢„ç®—æ§åˆ¶\n",
    "- æ¶ˆæ¯æˆªæ–­\n",
    "- æ•æ„Ÿè¯è¿‡æ»¤\n",
    "- ç”¨æˆ·æ•æ„Ÿä¿¡æ¯è¿‡æ»¤\n",
    "\n",
    "## ä¸€ã€é¢„ç®—æ§åˆ¶\n",
    "\n",
    "éšç€å¯¹è¯è½®æ¬¡å¢åŠ ï¼Œç§¯ç´¯çš„å†å²å¯¹è¯è¶Šæ¥è¶Šå¤šï¼Œæ¯æ¬¡è¯·æ±‚çš„è´¹ç”¨ä¹Ÿéšä¹‹å¢åŠ ã€‚ä¸ºäº†æ§åˆ¶é¢„ç®—ï¼Œæˆ‘ä»¬å¯ä»¥è®¾å®šåœ¨å¯¹è¯è¶…è¿‡æŸä¸ªè½®æ¬¡ä¹‹åï¼Œåˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ã€‚è¯¥åŠŸèƒ½å¯ä»¥é€šè¿‡ä¸­é—´ä»¶å®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd14ba5-4b0c-4cfb-a976-040d0a365f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# åŠ è½½æ¨¡å‹é…ç½®\n",
    "_ = load_dotenv()\n",
    "\n",
    "# ä½è´¹ç‡æ¨¡å‹\n",
    "basic_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    ")\n",
    "\n",
    "# é«˜è´¹ç‡æ¨¡å‹\n",
    "advanced_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"Qwen/Qwen3-32B\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4033cbf-b59f-4a6b-9fd1-f102b7fea252",
   "metadata": {},
   "source": [
    "å…·ä½“æ¥è¯´ï¼Œä¸‹é¢çš„é¢„ç®—æ§åˆ¶åŠŸèƒ½æ˜¯é€šè¿‡ä¸€ä¸ªå« [`@wrap_model_call`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_model_call) çš„è£…é¥°å™¨ï¼Œæ‰€è£…é¥°çš„ä¸­é—´ä»¶å®ç°çš„ã€‚\n",
    "\n",
    "[æ¥å£æ–‡æ¡£](https://reference.langchain.com/python/langchain/middleware/) ä¸­å¯ä»¥æ‰¾åˆ°æ‰€æœ‰è£…é¥°å™¨ï¼š\n",
    "\n",
    "- `@before_agent`: å°è£…åœ¨ Agent æ‰§è¡Œä¹‹å‰æ‰§è¡Œçš„é€»è¾‘\n",
    "- `@before_model`: å°è£…åœ¨æ¨¡å‹è°ƒç”¨ä¹‹å‰æ‰§è¡Œçš„é€»è¾‘\n",
    "- `@after_agent`: å°è£…åœ¨ Agent æ‰§è¡Œä¹‹åæ‰§è¡Œçš„é€»è¾‘\n",
    "- `@after_model`: å°è£…åœ¨æ¨¡å‹è°ƒç”¨ä¹‹åæ‰§è¡Œçš„é€»è¾‘\n",
    "- `@wrap_model_call`: æ§åˆ¶æ¨¡å‹è°ƒç”¨è¿‡ç¨‹\n",
    "- `@wrap_tool_call`: æ§åˆ¶å·¥å…·è°ƒç”¨è¿‡ç¨‹\n",
    "- `@dynamic_prompt`: åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯\n",
    "- `@hook_config`: é…ç½®é’©å­è¡Œä¸º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e758792-47d8-4ea4-857e-dddbbc71eb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x114723680>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 3:\n",
    "        # Use an advanced model for longer conversations\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "\n",
    "    request.model = model\n",
    "    print(f\"message_count: {message_count}\")\n",
    "    print(f\"model_name: {model.model_name}\")\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,  # Default model\n",
    "    middleware=[dynamic_model_selection]\n",
    ")\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b4ed25-2ef8-4a24-9760-89f1ed34bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 ===\n",
      "message_count: 1\n",
      "model_name: Qwen/Qwen3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/8fxvkyrx5cx5k_2l94yt12640000gn/T/ipykernel_3087/587980093.py:12: DeprecationWarning: Direct attribute assignment to ModelRequest.model is deprecated. Use request.override(model=...) instead to create a new request with the modified attribute.\n",
      "  request.model = model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: æ±½è½¦é€šå¸¸æœ‰å››ä¸ªè½®å­ã€‚\n",
      "\n",
      "=== Round 2 ===\n",
      "message_count: 3\n",
      "model_name: Qwen/Qwen3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/8fxvkyrx5cx5k_2l94yt12640000gn/T/ipykernel_3087/587980093.py:12: DeprecationWarning: Direct attribute assignment to ModelRequest.model is deprecated. Use request.override(model=...) instead to create a new request with the modified attribute.\n",
      "  request.model = model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: é£æœºé€šå¸¸æœ‰å¤šä¸ªè½®å­ï¼Œå…·ä½“æ•°é‡å› é£æœºç±»å‹è€Œå¼‚ã€‚å¤§å¤šæ•°å•†ç”¨å®¢æœºæœ‰**8ä¸ªè½®å­**ï¼ˆ4ä¸ªä¸»è½®å’Œ2ä¸ªå‰è½®ï¼‰ï¼Œä½†ä¹Ÿæœ‰ä¾‹å¤–ï¼Œå¦‚ä¸€äº›å°å‹é£æœºå¯èƒ½åªæœ‰**2åˆ°4ä¸ªè½®å­**ã€‚\n",
      "\n",
      "=== Round 3 ===\n",
      "message_count: 5\n",
      "model_name: Qwen/Qwen3-32B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/8fxvkyrx5cx5k_2l94yt12640000gn/T/ipykernel_3087/587980093.py:12: DeprecationWarning: Direct attribute assignment to ModelRequest.model is deprecated. Use request.override(model=...) instead to create a new request with the modified attribute.\n",
      "  request.model = model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: æ‘©æ‰˜è½¦é€šå¸¸æœ‰**ä¸¤ä¸ªè½®å­**ã€‚\n",
      "\n",
      "=== Round 4 ===\n",
      "message_count: 7\n",
      "model_name: Qwen/Qwen3-32B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/8fxvkyrx5cx5k_2l94yt12640000gn/T/ipykernel_3087/587980093.py:12: DeprecationWarning: Direct attribute assignment to ModelRequest.model is deprecated. Use request.override(model=...) instead to create a new request with the modified attribute.\n",
      "  request.model = model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: \n",
      "\n",
      "è‡ªè¡Œè½¦é€šå¸¸æœ‰**2ä¸ªè½®å­**ã€‚\n"
     ]
    }
   ],
   "source": [
    "state: MessagesState = {\"messages\": []}\n",
    "items = ['æ±½è½¦', 'é£æœº', 'æ‘©æ‰˜è½¦', 'è‡ªè¡Œè½¦']\n",
    "for idx, i in enumerate(items):\n",
    "    print(f\"\\n=== Round {idx+1} ===\")\n",
    "    state[\"messages\"] += [HumanMessage(content=f\"{i}æœ‰å‡ ä¸ªè½®å­ï¼Œè¯·ç®€å•å›ç­”\")]\n",
    "    result = agent.invoke(state)\n",
    "    state[\"messages\"] = result[\"messages\"]\n",
    "    print(f\"content: {result[\"messages\"][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc58247-324d-40fe-83e5-b34f9ec564e6",
   "metadata": {},
   "source": [
    "## äºŒã€æ¶ˆæ¯æˆªæ–­\n",
    "\n",
    "æ™ºèƒ½ä½“ç³»ç»Ÿä¸Šä¸‹æ–‡é•¿åº¦æ˜¯æœ‰é™ã€‚è‹¥è¶…è¿‡é™åˆ¶ï¼Œå°±åº”è¯¥æƒ³åŠæ³•å‹ç¼©ä¸Šä¸‹æ–‡ã€‚åœ¨æ‰€æœ‰æ–¹æ³•ä¸­ï¼Œæœ€ç®€å•ç²—æš´çš„å°±æ˜¯æˆªæ–­ã€‚æˆªæ–­åŠŸèƒ½å¯ä»¥åˆ©ç”¨ `@before_model` è£…é¥°å™¨å®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08619c1-6940-4043-be1b-3282be16c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750eee1-a873-424c-878b-61ec5bf81f0e",
   "metadata": {},
   "source": [
    "åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œç”±äºæˆ‘ä»¬åœ¨ç¬¬ä¸€æ¡æ¶ˆæ¯ä¸­å‘Šè¯‰æ™ºèƒ½ä½“æˆ‘å« bobï¼Œå¹¶ä¸”è®©æ™ºèƒ½ä½“å§‹ç»ˆä¿ç•™ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œå› æ­¤æ™ºèƒ½ä½“æ€»æ˜¯è®°å¾—æˆ‘æ˜¯ bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aefc09f4-d67f-4a7a-b930-171043e0a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! ğŸ˜Š  \n",
      "Let me know if you'd like a poem about Bob or anything elseâ€”maybe even a poem about Bob the dog?\n"
     ]
    }
   ],
   "source": [
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    basic_model,\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "def agent_invoke(agent):\n",
    "    agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "    agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "    agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "    final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "    \n",
    "    final_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "agent_invoke(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2afa04-18ad-487d-9cef-dfba0b5ec36d",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œå¯¹ä¸­é—´ä»¶åšä¸€äº›æ›´æ”¹ã€‚æ”¹ä¸ºä¿ç•™æœ€åä¸¤æ¡å¯¹è¯è®°å½•ï¼Œç°åœ¨æ™ºèƒ½ä½“ä¸è®°å¾—æˆ‘æ˜¯ bob äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc2a8e62-b7c4-4275-8967-7c551a73c6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't know your name yet, but I'm here to learn it! What's your name? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "@before_model\n",
    "def trim_without_first_message(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *messages[-2:]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    basic_model,\n",
    "    middleware=[trim_without_first_message],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "agent_invoke(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1220c4b-13f2-48e0-90d8-3fb2bc92e5bd",
   "metadata": {},
   "source": [
    "## ä¸‰ã€æŠ¤æ ï¼šæ•æ„Ÿè¯è¿‡æ»¤\n",
    "\n",
    "æŠ¤æ ï¼ˆGuardrailsï¼‰æ˜¯æ™ºèƒ½ä½“æä¾›çš„ä¸€ç±»å†…å®¹å®‰å…¨èƒ½åŠ›çš„ç»Ÿç§°ã€‚æˆ‘ä»¬çŸ¥é“æ¨¡å‹æœ¬èº«æ˜¯æœ‰å†…å®¹å®‰å…¨èƒ½åŠ›çš„ï¼Œä½†å¾ˆå®¹æ˜“è¢«ç»•è¿‡ï¼Œè¿™ä¸€èˆ¬è¢«ç§°ä¸ºç ´ç”²æˆ–è€…ç ´é™ã€‚æ™ºèƒ½ä½“å¯ä»¥åœ¨æ¨¡å‹ä¹‹å¤–æä¾›é¢å¤–çš„å®‰å…¨èƒ½åŠ›ã€‚è¿™æ˜¯é€šè¿‡å·¥ç¨‹ä¸Šçš„å¼ºåˆ¶æ€§æ£€æŸ¥å®ç°çš„ã€‚\n",
    "\n",
    "åœ¨ LangGraph ä¸­ï¼ŒæŠ¤æ å¯ä»¥é€šè¿‡ä¸­é—´ä»¶å®ç°ã€‚ä¸‹é¢æˆ‘ä»¬å®ç°ä¸€ä¸ªç®€å•çš„â€œæŠ¤æ â€ï¼šè‹¥ç”¨æˆ·æœ€æ–°ä¸€æ¡è¾“å…¥ä¸­åŒ…å«æŒ‡å®šçš„æ•æ„Ÿè¯ï¼Œåˆ™æ™ºèƒ½ä½“æ‹’ç»å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c5cc5b-7b4a-4658-8f86-feb8114d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain.agents.middleware import before_agent, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "banned_keywords = [\"hack\", \"exploit\", \"malware\"]\n",
    "\n",
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_filter(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "\n",
    "    # Check for banned keywords\n",
    "    for keyword in banned_keywords:\n",
    "        if keyword in content:\n",
    "            # Block execution before any processing\n",
    "            return {\n",
    "                \"messages\": [{\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "                }],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,\n",
    "    middleware=[content_filter],\n",
    ")\n",
    "\n",
    "# This request will be blocked before any processing\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55cad2e8-ab78-44d6-8682-1e0fe17469a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How do I hack into a database?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I cannot process requests containing inappropriate content. Please rephrase your request.\n"
     ]
    }
   ],
   "source": [
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761479b-d432-4e09-9341-4b5ad8363b48",
   "metadata": {},
   "source": [
    "## å››ã€æŠ¤æ ï¼šPII æ£€æµ‹\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç»§ç»­ç¼–å†™æŠ¤æ ã€‚[PII](https://docs.langchain.com/oss/python/langchain/guardrails#pii-detection)ï¼ˆPersonally Identifiable Informationï¼‰æ£€æµ‹æ˜¯ä¸€ä¸ªè¿‡æ»¤ç”¨æˆ·æ•æ„Ÿä¿¡æ¯çš„æŠ¤æ åŠŸèƒ½ã€‚åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†æ£€æµ‹ç”¨æˆ·çš„é‚®ç®±ã€IPã€åœ°å€ã€é“¶è¡Œå¡ç­‰æ•æ„Ÿä¿¡æ¯ã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†å°è¯•ä¸¤ç§ç­–ç•¥å¤„ç†æ£€æµ‹åˆ°çš„æ•æ„Ÿä¿¡æ¯ï¼š\n",
    "1. æ‹’ç»å›ç­”ç”¨æˆ·çš„é—®é¢˜\n",
    "2. å°†æ•æ„Ÿä¿¡æ¯æ›¿æ¢ä¸ºä¸€è¿ä¸²çš„æ˜Ÿå· `********`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0697a36-a7f6-46dc-acf0-44eed2c56daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# å¯ä¿¡ä»»çš„æ¨¡å‹ï¼Œä¸€èˆ¬æ˜¯æœ¬åœ°æ¨¡å‹ï¼Œä¸ºäº†æ–¹ä¾¿ï¼Œè¿™é‡Œä¾ç„¶ä½¿ç”¨qwen\n",
    "trusted_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    ")\n",
    "\n",
    "# ç”¨äºæ ¼å¼åŒ–æ™ºèƒ½ä½“è¾“å‡ºï¼Œè‹¥å‘ç°æ•æ„Ÿä¿¡æ¯è¿”å›Trueï¼Œæ²¡å‘ç°è¿”å›False\n",
    "class PiiCheck(BaseModel):\n",
    "    \"\"\"Structured output indicating whether text contains PII.\"\"\"\n",
    "    is_pii: bool = Field(description=\"Whether the text contains PII\")\n",
    "\n",
    "def message_with_pii(pii_middleware):\n",
    "    agent = create_agent(\n",
    "        model=basic_model,\n",
    "        middleware=[pii_middleware],\n",
    "    )\n",
    "\n",
    "    # This request will be blocked before any processing\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": dedent(\n",
    "                \"\"\"\n",
    "                File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
    "                    agent = create_react_agent(\n",
    "                            ^^^^^^^^^^^^^^^^^^^\n",
    "                File \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n",
    "                    return arg(*args, **kwargs)\n",
    "                        ^^^^^^^^^^^^^^^^^^^^\n",
    "                File \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n",
    "                    model = cast(BaseChatModel, model).bind_tools(\n",
    "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "                AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n",
    "    \n",
    "                ---\n",
    "    \n",
    "                ä¸ºå•¥æŠ¥é”™\n",
    "                \"\"\").strip()\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b344fe-5bb5-4349-9183-ed163b5fde4a",
   "metadata": {},
   "source": [
    "**ç­–ç•¥ä¸€**ï¼šå¦‚é‡æ•æ„Ÿä¿¡æ¯ï¼Œæ‹’ç»å›å¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6400b371-034f-4c71-8dd6-6c5f115a0b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_blocker(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "    prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·è¯†åˆ«ä¸‹é¢æ–‡æœ¬ä¸­æ¶‰åŠä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ï¼Œ\"\n",
    "        \"ä¾‹å¦‚ï¼šå§“åã€èº«ä»½è¯å·ã€æŠ¤ç…§å·ã€ç”µè¯å·ç ã€é‚®ç®±ã€ä½å€ã€é“¶è¡Œå¡å·ã€ç¤¾äº¤è´¦å·ã€è½¦ç‰Œç­‰ã€‚\"\n",
    "        \"ç‰¹åˆ«æ³¨æ„ï¼Œè‹¥ä»£ç ã€æ–‡ä»¶è·¯å¾„ä¸­åŒ…å«ç”¨æˆ·åï¼Œä¹Ÿåº”è¢«è§†ä¸ºæ•æ„Ÿä¿¡æ¯ã€‚\"\n",
    "        \"è‹¥åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œè¯·è¿”å›{\\\"is_pii\\\": True}ï¼Œå¦åˆ™è¿”å›{\\\"is_pii\\\": False}ã€‚\"\n",
    "        \"è¯·ä¸¥æ ¼ä»¥ json æ ¼å¼è¿”å›ï¼Œå¹¶ä¸”åªè¾“å‡º jsonã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + content\n",
    "    )\n",
    "\n",
    "    pii_agent = trusted_model.with_structured_output(PiiCheck)\n",
    "    result = pii_agent.invoke(prompt)\n",
    "\n",
    "    if result.is_pii is True:\n",
    "        # Block execution before any processing\n",
    "        return {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "            }],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "    else:\n",
    "        print(\"No PII found\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09ba27fa-cb71-4dd2-b051-7ef949d1cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n",
      "    return arg(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n",
      "    model = cast(BaseChatModel, model).bind_tools(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n",
      "\n",
      "---\n",
      "\n",
      "ä¸ºå•¥æŠ¥é”™\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I cannot process requests containing inappropriate content. Please rephrase your request.\n"
     ]
    }
   ],
   "source": [
    "result = message_with_pii(pii_middleware=content_blocker)\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9ad2b-18f9-41e1-995b-81572753f4d2",
   "metadata": {},
   "source": [
    "**ç­–ç•¥äºŒ**ï¼šå¦‚é‡æ•æ„Ÿä¿¡æ¯ï¼Œä½¿ç”¨ `*` å·å±è”½æ•æ„Ÿä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7a946d8-fde3-4348-82e4-3801481a332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_filter(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "    prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·è¯†åˆ«ä¸‹é¢æ–‡æœ¬ä¸­æ¶‰åŠä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ï¼Œ\"\n",
    "        \"ä¾‹å¦‚ï¼šå§“åã€èº«ä»½è¯å·ã€æŠ¤ç…§å·ã€ç”µè¯å·ç ã€é‚®ç®±ã€ä½å€ã€é“¶è¡Œå¡å·ã€ç¤¾äº¤è´¦å·ã€è½¦ç‰Œç­‰ã€‚\"\n",
    "        \"ç‰¹åˆ«æ³¨æ„ï¼Œè‹¥ä»£ç ã€æ–‡ä»¶è·¯å¾„ä¸­åŒ…å«ç”¨æˆ·åï¼Œä¹Ÿåº”è¢«è§†ä¸ºæ•æ„Ÿä¿¡æ¯ã€‚\"\n",
    "        \"è‹¥åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œè¯·è¿”å›{\\\"is_pii\\\": True}ï¼Œå¦åˆ™è¿”å›{\\\"is_pii\\\": False}ã€‚\"\n",
    "        \"è¯·ä¸¥æ ¼ä»¥ json æ ¼å¼è¿”å›ï¼Œå¹¶ä¸”åªè¾“å‡º jsonã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + content\n",
    "    )\n",
    "\n",
    "    pii_agent = trusted_model.with_structured_output(PiiCheck)\n",
    "    result = pii_agent.invoke(prompt)\n",
    "\n",
    "    if result.is_pii is True:\n",
    "        mask_prompt = (\n",
    "            \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·å°†ä¸‹é¢æ–‡æœ¬ä¸­çš„æ‰€æœ‰ä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ç”¨æ˜Ÿå·ï¼ˆ*ï¼‰æ›¿æ¢ã€‚\"\n",
    "            \"ä»…æ›¿æ¢æ•æ„Ÿç‰‡æ®µï¼Œå…¶ä»–æ–‡æœ¬ä¿æŒä¸å˜ã€‚\"\n",
    "            \"åªè¾“å‡ºå¤„ç†åçš„æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–é¢å¤–å†…å®¹ã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + last_message.content\n",
    "        )\n",
    "        masked_message = basic_model.invoke(mask_prompt)\n",
    "        return {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": masked_message.content\n",
    "            }]\n",
    "        }\n",
    "    else:\n",
    "        print(\"No PII found\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2480e24d-39b9-4329-a008-6b162850f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No PII found\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n",
      "    return arg(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "File \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n",
      "    model = cast(BaseChatModel, model).bind_tools(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n",
      "\n",
      "---\n",
      "\n",
      "ä¸ºå•¥æŠ¥é”™\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ é‡åˆ°çš„è¿™ä¸ªé”™è¯¯ä¿¡æ¯æ˜¯ï¼š\n",
      "\n",
      "```\n",
      "AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n",
      "```\n",
      "\n",
      "ä»é”™è¯¯ä¿¡æ¯æ¥çœ‹ï¼Œä½ çš„ä»£ç ä¸­è°ƒç”¨äº† `create_react_agent` å‡½æ•°ï¼Œä½†ä¼ å…¥çš„æ¨¡å‹å¯¹è±¡æ˜¯ä¸€ä¸ª `RunnableLambda` ç±»å‹ï¼Œè€Œä¸æ˜¯æ”¯æŒ `bind_tools` æ–¹æ³•çš„é‚£ä¸ªæ¨¡å‹ç±»å‹ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… é”™è¯¯åŸå› è§£é‡Šï¼š\n",
      "\n",
      "`bind_tools` æ–¹æ³•é€šå¸¸æ˜¯ `BaseChatModel` ç±»ï¼ˆæˆ–å…¶å­ç±»å¦‚ `ChatOpenAI`ï¼‰çš„ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºå°†å¤–éƒ¨å·¥å…·ç»‘å®šåˆ°æ¨¡å‹ä¸­ï¼Œä»è€Œå®ç°æ¨¡å‹è°ƒç”¨è¿™äº›å·¥å…·çš„èƒ½åŠ›ã€‚è€Œ `RunnableLambda` æ˜¯æ¥è‡ª `langchain` æˆ– `langgraph` çš„ä¸€ä¸ªå‡½æ•°å¼ç»„ä»¶ï¼Œç”¨æ¥æ„å»ºå¯æ‰§è¡Œçš„æµç¨‹ï¼Œå®ƒæœ¬èº«**å¹¶ä¸å…·å¤‡** `bind_tools` æ–¹æ³•ã€‚\n",
      "\n",
      "è¿™è¯´æ˜ä½ å¯èƒ½å°†ä¸€ä¸ª `RunnableLambda` å¯¹è±¡é”™è¯¯åœ°ä¼ ç»™äº† `create_react_agent` å‡½æ•°ï¼Œä½œä¸ºå®ƒçš„æ¨¡å‹å‚æ•°ã€‚`create_react_agent` æœŸæœ›çš„æ˜¯ä¸€ä¸ªæ”¯æŒ `bind_tools` æ–¹æ³•çš„æ¨¡å‹ï¼ˆæ¯”å¦‚ `ChatOpenAI`ã€`ChatGoogleGemini` ç­‰è¯­è¨€æ¨¡å‹ç±»ï¼‰ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå¯æ‰§è¡Œ Lambdaã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… è§£å†³æ–¹æ³•ï¼š\n",
      "\n",
      "ä½ éœ€è¦ç¡®è®¤ä½ æ˜¯å¦æ­£ç¡®åœ°å°†**è¯­è¨€æ¨¡å‹å¯¹è±¡**ä¼ å…¥ `create_react_agent`ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå‡½æ•°æˆ– `RunnableLambda`ã€‚\n",
      "\n",
      "#### â—ç¤ºä¾‹é”™è¯¯ä»£ç ï¼ˆå¯èƒ½æ˜¯ä½ å†™çš„ï¼‰ï¼š\n",
      "\n",
      "```python\n",
      "from langchain_core.runnables import RunnableLambda\n",
      "from langgraph.prebuilt import create_react_agent\n",
      "\n",
      "def my_function(text):\n",
      "    return f\"Processed: {text}\"\n",
      "\n",
      "agent = create_react_agent(RunnableLambda(my_function))\n",
      "```\n",
      "\n",
      "#### âœ… æ­£ç¡®åšæ³•ï¼š\n",
      "\n",
      "ä½ éœ€è¦ä½¿ç”¨ä¸€ä¸ªæ”¯æŒ `bind_tools` çš„è¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚ `ChatOpenAI` æˆ– `ChatGoogleGemini`ï¼Œå¹¶å°†ç³»ç»Ÿæç¤ºï¼ˆsystem promptï¼‰ä½œä¸ºå‚æ•°ä¼ å…¥ã€‚\n",
      "\n",
      "#### ğŸ“Œ ç¤ºä¾‹æ­£ç¡®ä»£ç ï¼š\n",
      "\n",
      "```python\n",
      "from langchain_openai import ChatOpenAI\n",
      "from langgraph.prebuilt import create_react_agent\n",
      "\n",
      "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
      "agent = create_react_agent(llm, system_prompt=\"You are a helpful assistant.\")\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… ä½ å¯èƒ½åœ¨åšä»€ä¹ˆï¼Ÿ\n",
      "\n",
      "ä½ å¾ˆå¯èƒ½åœ¨ä½¿ç”¨ `langgraph` çš„ `create_react_agent` æ–¹æ³•ï¼Œå®ƒæœŸæœ›ä¸€ä¸ªè¯­è¨€æ¨¡å‹å¯¹è±¡ï¼ˆæ¯”å¦‚ `ChatOpenAI`ï¼‰ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå¯æ‰§è¡Œå‡½æ•°ï¼ˆå¦‚ `RunnableLambda` æˆ– `lambda`ï¼‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… æ€»ç»“ï¼š\n",
      "\n",
      "- **é”™è¯¯æ¥æº**ï¼šä½ ä¼ å…¥äº† `RunnableLambda` ä½œä¸ºæ¨¡å‹å‚æ•°ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ”¯æŒ `bind_tools` çš„è¯­è¨€æ¨¡å‹ã€‚\n",
      "- **è§£å†³æ–¹æ³•**ï¼šç¡®ä¿ä½ ä¼ å…¥çš„æ˜¯ä¸€ä¸ªæ”¯æŒ `bind_tools` æ–¹æ³•çš„è¯­è¨€æ¨¡å‹å¯¹è±¡ï¼ˆå¦‚ `ChatOpenAI`ï¼‰ã€‚\n",
      "- **æ­£ç¡®æ–¹å¼**ï¼šä½¿ç”¨ä¸€ä¸ª `ChatModel` ç±»ï¼ˆå¦‚ `ChatOpenAI`ï¼‰å®ä¾‹ï¼Œå¹¶å°†å…¶ä½œä¸º `create_react_agent` çš„ç¬¬ä¸€ä¸ªå‚æ•°ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "å¦‚æœä½ èƒ½æä¾›ä½ ä½¿ç”¨çš„ `create_react_agent` çš„å®Œæ•´è°ƒç”¨æ–¹å¼ï¼Œæˆ‘å¯ä»¥æ›´å…·ä½“åœ°å¸®åŠ©ä½ å®šä½é—®é¢˜ã€‚ä½†æ˜¯ä»ä½ ç»™å‡ºçš„ä¿¡æ¯æ¥çœ‹ï¼Œé—®é¢˜åœ¨äºä½ ä½¿ç”¨äº†é”™è¯¯ç±»å‹çš„æ¨¡å‹å‚æ•°ã€‚\n"
     ]
    }
   ],
   "source": [
    "result = message_with_pii(pii_middleware=content_filter)\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d7771-f9b8-4408-9387-c67c51c1a155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dive-into-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
